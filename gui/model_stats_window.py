# gui/model_stats_window.py - –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∏–º–ø–æ—Ä—Ç–∞–º–∏

import tkinter as tk
from tkinter import ttk
import matplotlib.pyplot as plt

# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ –≤–µ—Ä—Å–∏—è–º–∏ matplotlib
try:
    from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg as FigureCanvas
except ImportError:
    try:
        from matplotlib.backends.backend_tkagg import FigureCanvasTk as FigureCanvas
    except ImportError:
        # Fallback –¥–ª—è –æ—á–µ–Ω—å —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π
        from matplotlib.backends.backend_tkagg import FigureCanvasTkinter as FigureCanvas

import numpy as np
from typing import Dict, List, Tuple, Any
from datetime import datetime, timedelta

from models.user import User
from auth.keystroke_auth import KeystrokeAuthenticator
from ml.model_manager import ModelManager
from utils.database import DatabaseManager
from config import FONT_FAMILY

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ matplotlib –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å tkinter
plt.style.use('default')

class ModelStatsWindow:
    """–û–∫–Ω–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –º–æ–¥–µ–ª–∏ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
    
    def __init__(self, parent, user: User, keystroke_auth: KeystrokeAuthenticator):
        self.parent = parent
        self.user = user
        self.keystroke_auth = keystroke_auth
        self.model_manager = ModelManager()
        self.db = DatabaseManager()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –æ–∫–Ω–∞
        self.window = tk.Toplevel(parent)
        self.window.title(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏ - {user.username}")
        self.window.geometry("1000x700")
        self.window.resizable(True, True)
        
        # –ú–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ
        self.window.transient(parent)
        self.window.grab_set()
        
        # –î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        self.training_samples = self.db.get_user_training_samples(user.id)
        self.model_info = self.model_manager.get_model_info(user.id)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
        self.create_widgets()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.load_real_statistics()
    
    def create_widgets(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–¥–∂–µ—Ç–æ–≤ –æ–∫–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        # Notebook –¥–ª—è –≤–∫–ª–∞–¥–æ–∫
        self.notebook = ttk.Notebook(self.window)
        self.notebook.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # –í–∫–ª–∞–¥–∫–∞ 1: –û–±–∑–æ—Ä
        self.create_overview_tab()
        
        # –í–∫–ª–∞–¥–∫–∞ 2: –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self.create_features_tab()
        
        # –í–∫–ª–∞–¥–∫–∞ 3: –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–º–µ—Ç—Ä–∏–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏)
        self.create_performance_tab()
        
        # –í–∫–ª–∞–¥–∫–∞ 4: ROC-–∫—Ä–∏–≤–∞—è –∏ –º–µ—Ç—Ä–∏–∫–∏
        self.create_roc_tab()
        
        # –í–∫–ª–∞–¥–∫–∞ 5: –î–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–∑—Ü–æ–≤
        self.create_samples_tab()
    
    def create_overview_tab(self):
        """–í–∫–ª–∞–¥–∫–∞ –æ–±–∑–æ—Ä–∞ –º–æ–¥–µ–ª–∏"""
        frame = ttk.Frame(self.notebook, padding=20)
        self.notebook.add(frame, text="–û–±–∑–æ—Ä")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        info_frame = ttk.LabelFrame(frame, text="–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏", padding=15)
        info_frame.pack(fill=tk.X, pady=(0, 20))
        
        self.overview_text = tk.Text(info_frame, height=8, width=70, font=(FONT_FAMILY, 10))
        self.overview_text.pack(fill=tk.BOTH, expand=True)
        
        # –ì—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–±—Ä–∞–∑—Ü–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        chart_frame = ttk.LabelFrame(frame, text="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏", padding=15)
        chart_frame.pack(fill=tk.BOTH, expand=True)
        
        self.fig1, self.ax1 = plt.subplots(figsize=(10, 4))
        self.canvas1 = FigureCanvas(self.fig1, chart_frame)
        self.canvas1.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    
    def create_features_tab(self):
        """–í–∫–ª–∞–¥–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        frame = ttk.Frame(self.notebook, padding=20)
        self.notebook.add(frame, text="–ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self.fig2, ((self.ax2a, self.ax2b), (self.ax2c, self.ax2d)) = plt.subplots(2, 2, figsize=(12, 8))
        self.canvas2 = FigureCanvas(self.fig2, frame)
        self.canvas2.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    
    def create_performance_tab(self):
        """–í–∫–ª–∞–¥–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        frame = ttk.Frame(self.notebook, padding=20)
        self.notebook.add(frame, text="–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å")
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        metrics_frame = ttk.LabelFrame(frame, text="–ú–µ—Ç—Ä–∏–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã", padding=15)
        metrics_frame.pack(fill=tk.X, pady=(0, 20))
        
        self.metrics_text = tk.Text(metrics_frame, height=12, width=80, font=(FONT_FAMILY, 10))
        self.metrics_text.pack(fill=tk.BOTH, expand=True)
        
        # –ì—Ä–∞—Ñ–∏–∫ –º–µ—Ç—Ä–∏–∫
        chart_frame = ttk.LabelFrame(frame, text="–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫", padding=15)
        chart_frame.pack(fill=tk.BOTH, expand=True)
        
        self.fig3, self.ax3 = plt.subplots(figsize=(10, 5))
        self.canvas3 = FigureCanvas(self.fig3, chart_frame)
        self.canvas3.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    
    def create_roc_tab(self):
        """–í–∫–ª–∞–¥–∫–∞ ROC-–∞–Ω–∞–ª–∏–∑–∞"""
        frame = ttk.Frame(self.notebook, padding=20)
        self.notebook.add(frame, text="ROC-–∫—Ä–∏–≤–∞—è")
        
        self.fig4, (self.ax4a, self.ax4b) = plt.subplots(1, 2, figsize=(12, 5))
        self.canvas4 = FigureCanvas(self.fig4, frame)
        self.canvas4.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    
    def create_samples_tab(self):
        """–í–∫–ª–∞–¥–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤"""
        frame = ttk.Frame(self.notebook, padding=20)
        self.notebook.add(frame, text="–î–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–∑—Ü–æ–≤")
        
        # –¢–∞–±–ª–∏—Ü–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
        table_frame = ttk.LabelFrame(frame, text="–û–±—É—á–∞—é—â–∏–µ –æ–±—Ä–∞–∑—Ü—ã", padding=15)
        table_frame.pack(fill=tk.BOTH, expand=True)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ Treeview
        columns = ('‚Ññ', '–í—Ä–µ–º—è', 'Avg Dwell', 'Avg Flight', '–°–∫–æ—Ä–æ—Å—Ç—å', '–û–±—â–µ–µ –≤—Ä–µ–º—è')
        self.samples_tree = ttk.Treeview(table_frame, columns=columns, show='headings', height=15)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        for col in columns:
            self.samples_tree.heading(col, text=col)
            self.samples_tree.column(col, width=120)
        
        # –°–∫—Ä–æ–ª–ª–±–∞—Ä
        scrollbar = ttk.Scrollbar(table_frame, orient=tk.VERTICAL, command=self.samples_tree.yview)
        self.samples_tree.configure(yscrollcommand=scrollbar.set)
        
        # –†–∞–∑–º–µ—â–µ–Ω–∏–µ
        self.samples_tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
    
    def load_real_statistics(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Ä–∞—Å—á–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        try:
            # 1. –û–±–∑–æ—Ä –º–æ–¥–µ–ª–∏
            self.load_overview_stats()
            
            # 2. –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            self.load_features_analysis()
            
            # 3. –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            self.load_performance_metrics()
            
            # 4. ROC-–∞–Ω–∞–ª–∏–∑ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å sklearn)
            self.load_roc_analysis()
            
            # 5. –î–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–∑—Ü–æ–≤
            self.load_samples_data()
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            import traceback
            traceback.print_exc()
    
    def load_overview_stats(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±–∑–æ—Ä–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        n_samples = len(self.training_samples)
        
        if n_samples == 0:
            self.overview_text.insert(tk.END, "–ù–µ—Ç –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        features_data = []
        for sample in self.training_samples:
            if sample.features:
                features_data.append([
                    sample.features.get('avg_dwell_time', 0),
                    sample.features.get('avg_flight_time', 0),
                    sample.features.get('typing_speed', 0),
                    sample.features.get('total_typing_time', 0)
                ])
        
        if not features_data:
            self.overview_text.insert(tk.END, "–ü—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –¥–ª—è –æ–±—Ä–∞–∑—Ü–æ–≤")
            return
        
        features_array = np.array(features_data)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        overview_info = f"""–û–ë–ó–û–† –ú–û–î–ï–õ–ò –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {self.user.username}

–û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:
‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞—é—â–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {n_samples}
‚Ä¢ –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∞–∫–∫–∞—É–Ω—Ç–∞: {self.user.created_at.strftime('%d.%m.%Y %H:%M')}
‚Ä¢ –ü–æ—Å–ª–µ–¥–Ω–∏–π –≤—Ö–æ–¥: {self.user.last_login.strftime('%d.%m.%Y %H:%M') if self.user.last_login else '–ù–∏–∫–æ–≥–¥–∞'}
‚Ä¢ –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏: {'–û–±—É—á–µ–Ω–∞' if self.user.is_trained else '–ù–µ –æ–±—É—á–µ–Ω–∞'}

–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –ø–µ—á–∞—Ç–∏:
‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —É–¥–µ—Ä–∂–∞–Ω–∏—è –∫–ª–∞–≤–∏—à: {np.mean(features_array[:, 0])*1000:.1f} ¬± {np.std(features_array[:, 0])*1000:.1f} –º—Å
‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –º–µ–∂–¥—É –∫–ª–∞–≤–∏—à–∞–º–∏: {np.mean(features_array[:, 1])*1000:.1f} ¬± {np.std(features_array[:, 1])*1000:.1f} –º—Å  
‚Ä¢ –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å –ø–µ—á–∞—Ç–∏: {np.mean(features_array[:, 2]):.1f} ¬± {np.std(features_array[:, 2]):.1f} –∫–ª–∞–≤–∏—à/—Å–µ–∫
‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –æ–±—â–µ–µ –≤—Ä–µ–º—è: {np.mean(features_array[:, 3]):.1f} ¬± {np.std(features_array[:, 3]):.1f} —Å–µ–∫

–í–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏):
‚Ä¢ –í—Ä–µ–º—è —É–¥–µ—Ä–∂–∞–Ω–∏—è: {(np.std(features_array[:, 0])/np.mean(features_array[:, 0])*100):.1f}%
‚Ä¢ –í—Ä–µ–º—è –º–µ–∂–¥—É –∫–ª–∞–≤–∏—à–∞–º–∏: {(np.std(features_array[:, 1])/np.mean(features_array[:, 1])*100):.1f}%
‚Ä¢ –°–∫–æ—Ä–æ—Å—Ç—å –ø–µ—á–∞—Ç–∏: {(np.std(features_array[:, 2])/np.mean(features_array[:, 2])*100):.1f}%

–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:
‚Ä¢ –ù–∏–∑–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å (<15%) = —Å—Ç–∞–±–∏–ª—å–Ω–∞—è –ø–µ—á–∞—Ç—å
‚Ä¢ –°—Ä–µ–¥–Ω—è—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å (15-30%) = –æ–±—ã—á–Ω–∞—è –ø–µ—á–∞—Ç—å  
‚Ä¢ –í—ã—Å–æ–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å (>30%) = –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–∞—è –ø–µ—á–∞—Ç—å"""

        self.overview_text.insert(tk.END, overview_info)
        
        # –ì—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        try:
            timestamps = [sample.timestamp for sample in self.training_samples]
            self.ax1.hist([t.hour for t in timestamps], bins=24, alpha=0.7, color='skyblue', edgecolor='black')
            self.ax1.set_xlabel('–ß–∞—Å –¥–Ω—è')
            self.ax1.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤')
            self.ax1.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–±–æ—Ä–∞ –æ–±—Ä–∞–∑—Ü–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫')
            self.ax1.grid(True, alpha=0.3)
            self.canvas1.draw()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≥—Ä–∞—Ñ–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏: {e}")
    
    def load_features_analysis(self):
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        if not self.training_samples:
            return
        
        try:
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            features_data = []
            for sample in self.training_samples:
                if sample.features:
                    features_data.append([
                        sample.features.get('avg_dwell_time', 0) * 1000,  # –≤ –º—Å
                        sample.features.get('avg_flight_time', 0) * 1000,  # –≤ –º—Å
                        sample.features.get('typing_speed', 0),
                        sample.features.get('total_typing_time', 0)
                    ])
            
            if not features_data:
                return
            
            features_array = np.array(features_data)
            feature_names = ['–í—Ä–µ–º—è —É–¥–µ—Ä–∂–∞–Ω–∏—è (–º—Å)', '–í—Ä–µ–º—è –º–µ–∂–¥—É –∫–ª–∞–≤–∏—à–∞–º–∏ (–º—Å)', 
                            '–°–∫–æ—Ä–æ—Å—Ç—å (–∫–ª–∞–≤–∏—à/—Å–µ–∫)', '–û–±—â–µ–µ –≤—Ä–µ–º—è (—Å–µ–∫)']
            
            # –ß–µ—Ç—ã—Ä–µ –≥—Ä–∞—Ñ–∏–∫–∞
            axes = [self.ax2a, self.ax2b, self.ax2c, self.ax2d]
            
            for i, (ax, name) in enumerate(zip(axes, feature_names)):
                data = features_array[:, i]
                
                # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞
                ax.hist(data, bins=min(10, len(data)//2 + 1), alpha=0.7, color=f'C{i}', edgecolor='black')
                ax.axvline(np.mean(data), color='red', linestyle='--', linewidth=2, label=f'–°—Ä–µ–¥–Ω–µ–µ: {np.mean(data):.2f}')
                ax.set_xlabel(name)
                ax.set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
                ax.set_title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {name}')
                ax.legend()
                ax.grid(True, alpha=0.3)
            
            self.fig2.tight_layout()
            self.canvas2.draw()
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
    
    def load_performance_metrics(self):
        """–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö + —Å–∏–º—É–ª—è—Ü–∏—è"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∏–∑ keystroke_auth
            db = self.keystroke_auth.db


            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
            auth_attempts = db.get_auth_attempts(self.user.id, limit=50)
        
            if len(auth_attempts) < 3:
                metrics_info = f"""–ù–ï–î–û–°–¢–ê–¢–û–ß–ù–û –î–ê–ù–ù–´–• –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê

    –ù–∞–π–¥–µ–Ω–æ –ø–æ–ø—ã—Ç–æ–∫: {len(auth_attempts)}
    –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 3 –ø–æ–ø—ã—Ç–∫–∏ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏.

    üöÄ –ß–¢–û –°–î–ï–õ–ê–¢–¨:
    1. –í–æ–π–¥–∏—Ç–µ –≤ —Å–∏—Å—Ç–µ–º—É 3-5 —Ä–∞–∑ —Å –ü–†–ê–í–ò–õ–¨–ù–û–ô —Å–∫–æ—Ä–æ—Å—Ç—å—é
    2. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–æ–π—Ç–∏ 2-3 —Ä–∞–∑–∞ —Å –ú–ï–î–õ–ï–ù–ù–û–ô —Å–∫–æ—Ä–æ—Å—Ç—å—é  
    3. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–æ–π—Ç–∏ 2-3 —Ä–∞–∑–∞ —Å –ë–´–°–¢–†–û–ô —Å–∫–æ—Ä–æ—Å—Ç—å—é
    4. –í–µ—Ä–Ω–∏—Ç–µ—Å—å –∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ

    üí° –≠—Ç–æ –¥–∞—Å—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ FAR/FRR/EER"""
            
                self.metrics_text.insert(tk.END, metrics_info)
                return

            print(f"\nüìä –ü–†–ê–ö–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –ú–ï–¢–†–ò–ö")
            print(f"–†–µ–∞–ª—å–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫: {len(auth_attempts)}")

            # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤–∞—à–∏—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            high_confidence = [a for a in auth_attempts if a['final_confidence'] >= 0.7]  # –¢–æ—á–Ω–æ –≤—ã
            medium_confidence = [a for a in auth_attempts if 0.4 <= a['final_confidence'] < 0.7]  # –°–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ
            low_confidence = [a for a in auth_attempts if a['final_confidence'] < 0.4]  # –¢–æ—á–Ω–æ –Ω–µ –≤—ã

            # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            legitimate_attempts = high_confidence  # –≠—Ç–æ —Ç–æ—á–Ω–æ –≤—ã
            suspicious_attempts = medium_confidence + low_confidence  # –í–æ–∑–º–æ–∂–Ω—ã–µ –∏–º–∏—Ç–∞—Ü–∏–∏

            print(f"–í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (>70%): {len(high_confidence)}")
            print(f"–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (40-70%): {len(medium_confidence)}")  
            print(f"–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (<40%): {len(low_confidence)}")

            # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤
            thresholds = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]
            threshold_results = []

            for threshold in thresholds:
                # –°—á–∏—Ç–∞–µ–º, —á—Ç–æ –ø–æ–ø—ã—Ç–∫–∏ —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é - —ç—Ç–æ –≤—ã (legitimate)
                # –ü–æ–ø—ã—Ç–∫–∏ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é - —ç—Ç–æ –∏–º–∏—Ç–∞—Ç–æ—Ä—ã (impostor)
            
                # –õ–µ–≥–∏—Ç–∏–º–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ (–¥–æ–ª–∂–Ω—ã –ø—Ä–æ—Ö–æ–¥–∏—Ç—å)
                legit_passed = sum(1 for a in legitimate_attempts if a['final_confidence'] >= threshold)
                legit_total = len(legitimate_attempts) if legitimate_attempts else 1
            
                # "–ò–º–∏—Ç–∞—Ç–æ—Ä—ã" (–Ω–µ –¥–æ–ª–∂–Ω—ã –ø—Ä–æ—Ö–æ–¥–∏—Ç—å)  
                impostor_passed = sum(1 for a in suspicious_attempts if a['final_confidence'] >= threshold)
                impostor_total = len(suspicious_attempts) if suspicious_attempts else 1

                # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
                frr = ((legit_total - legit_passed) / legit_total) * 100  # –û—Ç–∫–ª–æ–Ω–∏–ª–∏ –≤–∞—Å
                far = (impostor_passed / impostor_total) * 100  # –ü—Ä–∏–Ω—è–ª–∏ –∏–º–∏—Ç–∞—Ç–æ—Ä–∞
                eer = (far + frr) / 2
                accuracy = ((legit_passed + (impostor_total - impostor_passed)) / (legit_total + impostor_total)) * 100

                threshold_results.append({
                    'threshold': threshold,
                    'far': far,
                    'frr': frr, 
                    'eer': eer,
                    'accuracy': accuracy,
                    'legit_passed': legit_passed,
                    'legit_total': legit_total,
                    'impostor_passed': impostor_passed,
                    'impostor_total': impostor_total
                })

            # –¢–µ–∫—É—â–∏–π –ø–æ—Ä–æ–≥ (–æ–±—ã—á–Ω–æ 0.75)
            current_threshold = 0.75
            current_result = min(threshold_results, key=lambda x: abs(x['threshold'] - current_threshold))
        
            # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π EER)
            optimal_result = min(threshold_results, key=lambda x: x['eer'])

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            all_confidences = [a['final_confidence'] for a in auth_attempts]
            legit_confidences = [a['final_confidence'] for a in legitimate_attempts]
            suspicious_confidences = [a['final_confidence'] for a in suspicious_attempts] if suspicious_attempts else [0]

            # –ê–Ω–∞–ª–∏–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (KNN, Distance, Features)
            avg_knn = np.mean([a['knn_confidence'] for a in auth_attempts])
            avg_distance = np.mean([a['distance_score'] for a in auth_attempts])  
            avg_features = np.mean([a['feature_score'] for a in auth_attempts])

            metrics_info = f"""–ü–†–ê–ö–¢–ò–ß–ï–°–ö–ò–ï –ú–ï–¢–†–ò–ö–ò –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:

üìä –ê–ù–ê–õ–ò–ó –í–ê–®–ò–• –†–ï–ê–õ–¨–ù–´–• –ü–û–ü–´–¢–û–ö:

–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ–ø—ã—Ç–æ–∫ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:
‚Ä¢ –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (>70%): {len(high_confidence)} –ø–æ–ø—ã—Ç–æ–∫ - "–¢–æ—á–Ω–æ –≤—ã"
‚Ä¢ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (40-70%): {len(medium_confidence)} –ø–æ–ø—ã—Ç–æ–∫ - "–í–æ–∑–º–æ–∂–Ω–æ –≤—ã"  
‚Ä¢ –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (<40%): {len(low_confidence)} –ø–æ–ø—ã—Ç–æ–∫ - "–°–∫–æ—Ä–µ–µ –Ω–µ –≤—ã"

üéØ –ú–ï–¢–†–ò–ö–ò –ü–†–ò –¢–ï–ö–£–©–ï–ú –ü–û–†–û–ì–ï ({current_threshold:.0%}):

FAR (False Acceptance Rate):
‚Ä¢ –ó–Ω–∞—á–µ–Ω–∏–µ: {current_result['far']:.1f}%
‚Ä¢ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: –ò–∑ {current_result['impostor_total']} –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–∏–Ω—è–ª–∞ {current_result['impostor_passed']}
‚Ä¢ –°—Ç–∞—Ç—É—Å: {'‚úÖ –û–¢–õ–ò–ß–ù–û' if current_result['far'] < 10 else '‚úÖ –•–û–†–û–®–û' if current_result['far'] < 25 else '‚ö†Ô∏è –°–†–ï–î–ù–ï' if current_result['far'] < 50 else '‚ùå –ü–õ–û–•–û'}

FRR (False Rejection Rate):
‚Ä¢ –ó–Ω–∞—á–µ–Ω–∏–µ: {current_result['frr']:.1f}%
‚Ä¢ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: –ò–∑ {current_result['legit_total']} —è–≤–Ω–æ –≤–∞—à–∏—Ö –ø–æ–ø—ã—Ç–æ–∫ —Å–∏—Å—Ç–µ–º–∞ –æ—Ç–∫–ª–æ–Ω–∏–ª–∞ {current_result['legit_total'] - current_result['legit_passed']}
‚Ä¢ –°—Ç–∞—Ç—É—Å: {'‚úÖ –û–¢–õ–ò–ß–ù–û' if current_result['frr'] < 15 else '‚úÖ –•–û–†–û–®–û' if current_result['frr'] < 30 else '‚ö†Ô∏è –°–†–ï–î–ù–ï' if current_result['frr'] < 50 else '‚ùå –ü–õ–û–•–û'}

EER (Equal Error Rate):
‚Ä¢ –ó–Ω–∞—á–µ–Ω–∏–µ: {current_result['eer']:.1f}%
‚Ä¢ –°—Ç–∞—Ç—É—Å: {'üèÜ –û–¢–õ–ò–ß–ù–û' if current_result['eer'] < 15 else '‚úÖ –•–û–†–û–®–û' if current_result['eer'] < 25 else '‚ö†Ô∏è –°–†–ï–î–ù–ï' if current_result['eer'] < 40 else '‚ùå –¢–†–ï–ë–£–ï–¢ –£–õ–£–ß–®–ï–ù–ò–Ø'}

–û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {current_result['accuracy']:.1f}%

üìà –ê–ù–ê–õ–ò–ó –£–í–ï–†–ï–ù–ù–û–°–¢–ò:
‚Ä¢ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–≤—Å–µ): {np.mean(all_confidences):.1%}
‚Ä¢ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (—è–≤–Ω–æ –≤—ã): {np.mean(legit_confidences):.1%}
‚Ä¢ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ): {np.mean(suspicious_confidences):.1%}
‚Ä¢ –†–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç—å: {abs(np.mean(legit_confidences) - np.mean(suspicious_confidences)):.1%}

üîß –ö–ê–ö –§–û–†–ú–ò–†–£–ï–¢–°–Ø –í–ê–®–ê –£–í–ï–†–ï–ù–ù–û–°–¢–¨ ~{np.mean(legit_confidences):.0%}:
‚Ä¢ KNN –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä: {avg_knn:.1%} (–æ—Å–Ω–æ–≤–Ω–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º)
‚Ä¢ –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π: {avg_distance:.1%} (–ø–æ—Ö–æ–∂–µ—Å—Ç—å –Ω–∞ –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ)
‚Ä¢ –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {avg_features:.1%} (—Ä–∞–∑—É–º–Ω–æ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫)

üéõÔ∏è –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø:
‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–æ—Ä–æ–≥: {optimal_result['threshold']:.0%}
‚Ä¢ EER –ø—Ä–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–º –ø–æ—Ä–æ–≥–µ: {optimal_result['eer']:.1f}%
‚Ä¢ {'üìà –ü–æ–≤—ã—Å—å—Ç–µ –ø–æ—Ä–æ–≥ –¥–ª—è –±–æ–ª—å—à–µ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏' if optimal_result['threshold'] > current_threshold else 'üìâ –ü–æ–Ω–∏–∑—å—Ç–µ –ø–æ—Ä–æ–≥ –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ—Ö–æ–¥–∏–º–æ—Å—Ç–∏' if optimal_result['threshold'] < current_threshold else '‚úÖ –¢–µ–∫—É—â–∏–π –ø–æ—Ä–æ–≥ –æ–ø—Ç–∏–º–∞–ª–µ–Ω'}

üìã –ò–°–¢–û–†–ò–Ø –ü–û–°–õ–ï–î–ù–ò–• –ü–û–ü–´–¢–û–ö:"""

            # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –ø–æ–ø—ã—Ç–∫–∏ —Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
            recent_attempts = auth_attempts[:10]
            for i, attempt in enumerate(recent_attempts, 1):
                confidence = attempt['final_confidence']
                result_icon = "‚úÖ" if attempt['result'] else "‚ùå"
            
                # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–∞ –ø–æ–ø—ã—Ç–∫–∏
                if confidence >= 0.7:
                    attempt_type = "üü¢ –Ø–≤–Ω–æ –≤—ã"
                elif confidence >= 0.4:
                    attempt_type = "üü° –°–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ"
                else:
                    attempt_type = "üî¥ –°–∫–æ—Ä–µ–µ –Ω–µ –≤—ã"
            
                time_str = attempt['timestamp'].strftime('%d.%m %H:%M')
                metrics_info += f"\n{i:2d}. {time_str} | {result_icon} {confidence:.1%} | {attempt_type}"

            metrics_info += f"""

üí° –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:
{self._interpret_practical_results(current_result, len(legitimate_attempts), len(suspicious_attempts))}

üöÄ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –£–õ–£–ß–®–ï–ù–ò–Ø –ú–ï–¢–†–ò–ö:
{self._get_practical_recommendations(auth_attempts, current_result, optimal_result)}

‚ö†Ô∏è –ú–ï–¢–û–î–û–õ–û–ì–ò–Ø: –ê–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –≤–∞—à–∏—Ö —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ–ø—ã—Ç–∫–∞—Ö –≤—Ö–æ–¥–∞.
–ü–æ–ø—ã—Ç–∫–∏ —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é —Å—á–∏—Ç–∞—é—Ç—Å—è –ª–µ–≥–∏—Ç–∏–º–Ω—ã–º–∏, —Å –Ω–∏–∑–∫–æ–π - –∏–º–∏—Ç–∞—Ü–∏–µ–π."""

            self.metrics_text.insert(tk.END, metrics_info)

            # –ì—Ä–∞—Ñ–∏–∫
            self._plot_practical_metrics(threshold_results, current_result, auth_attempts)

        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"
            self.metrics_text.insert(tk.END, error_msg)
            print(f"–û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def load_roc_analysis(self):
        """–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π ROC-–∞–Ω–∞–ª–∏–∑"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ sklearn
            from sklearn.metrics import roc_curve, auc
        
            classifier = self.model_manager._get_user_model(self.user.id)
            if not classifier or not classifier.is_trained:
                self.ax4a.text(0.5, 0.5, '–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞', 
                            ha='center', va='center', transform=self.ax4a.transAxes, fontsize=14)
                self.ax4b.text(0.5, 0.5, '–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞', 
                            ha='center', va='center', transform=self.ax4b.transAxes, fontsize=14)
                self.canvas4.draw()
                return

            # –ü–æ–ª—É—á–∞–µ–º –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            X_positive = classifier.training_data
            n_samples = len(X_positive)
        
            print(f"\nüìà ROC-–ê–ù–ê–õ–ò–ó —Å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏")

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (–∫–∞–∫ –≤ –º–µ—Ç—Ä–∏–∫–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
            # 1. –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –Ω–µ–≥–∞—Ç–∏–≤—ã
            X_negative_realistic = self._generate_realistic_negatives(X_positive, n_samples)
        
            # 2. –í–∞—à–∏ –≤–∞—Ä–∏–∞—Ü–∏–∏
            X_positive_variations = self._generate_user_variations(X_positive, int(n_samples * 0.3))
        
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ (–æ–±—É—á–∞—é—â–∏–µ + –≤–∞—Ä–∏–∞—Ü–∏–∏)
            X_all_positive = np.vstack([X_positive, X_positive_variations])
        
            # –°–æ–∑–¥–∞–µ–º —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä
            test_size = min(len(X_all_positive), len(X_negative_realistic))
        
            # –ë–µ—Ä–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –ø–æ–¥–≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –±–∞–ª–∞–Ω—Å–∞
            if len(X_all_positive) > test_size:
                pos_indices = np.random.choice(len(X_all_positive), test_size, replace=False)
                X_test_positive = X_all_positive[pos_indices]
            else:
                X_test_positive = X_all_positive
            
            if len(X_negative_realistic) > test_size:
                neg_indices = np.random.choice(len(X_negative_realistic), test_size, replace=False)
                X_test_negative = X_negative_realistic[neg_indices]
            else:
                X_test_negative = X_negative_realistic

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            X_test = np.vstack([X_test_positive, X_test_negative])
            y_test = np.hstack([
                np.ones(len(X_test_positive)),   # 1 = –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ
                np.zeros(len(X_test_negative))   # 0 = —á—É–∂–∏–µ –¥–∞–Ω–Ω—ã–µ
            ])

            print(f"–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è ROC: {len(X_test_positive)} –≤–∞—à–∏—Ö + {len(X_test_negative)} —á—É–∂–∏—Ö")

            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            y_proba = classifier.model.predict_proba(X_test)
        
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–ª–∞—Å—Å–∞ 1
            if y_proba.shape[1] == 2:
                y_scores = y_proba[:, 1]  # –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–ª–∞—Å—Å–∞ 1 (–≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ)
            else:
                # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∫–ª–∞—Å—Å
                y_scores = classifier.model.decision_function(X_test)

            # –°—Ç—Ä–æ–∏–º ROC –∫—Ä–∏–≤—É—é
            fpr, tpr, thresholds = roc_curve(y_test, y_scores)
            roc_auc = auc(fpr, tpr)

            # –ì—Ä–∞—Ñ–∏–∫ 1: ROC –∫—Ä–∏–≤–∞—è
            self.ax4a.clear()
            self.ax4a.plot(fpr, tpr, color='darkorange', lw=2, 
                        label=f'ROC –∫—Ä–∏–≤–∞—è (AUC = {roc_auc:.3f})')
            self.ax4a.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', 
                        label='–°–ª—É—á–∞–π–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (AUC = 0.5)')
        
            # –û—Ç–º–µ—á–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é —Ç–æ—á–∫—É (–º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ—Ç TPR - FPR)
            optimal_idx = np.argmax(tpr - fpr)
            optimal_threshold = thresholds[optimal_idx]
            self.ax4a.plot(fpr[optimal_idx], tpr[optimal_idx], 'ro', markersize=8, 
                        label=f'–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ = {optimal_threshold:.3f}')
        
            self.ax4a.set_xlim([0.0, 1.0])
            self.ax4a.set_ylim([0.0, 1.05])
            self.ax4a.set_xlabel('False Positive Rate (FAR)')
            self.ax4a.set_ylabel('True Positive Rate (1 - FRR)')
            self.ax4a.set_title(f'ROC –ö—Ä–∏–≤–∞—è (AUC = {roc_auc:.3f})')
            self.ax4a.legend(loc="lower right", fontsize=9)
            self.ax4a.grid(True, alpha=0.3)

            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é AUC
            if roc_auc >= 0.9:
                auc_interpretation = "–û—Ç–ª–∏—á–Ω–∞—è"
            elif roc_auc >= 0.8:
                auc_interpretation = "–•–æ—Ä–æ—à–∞—è"
            elif roc_auc >= 0.7:
                auc_interpretation = "–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–∞—è"
            else:
                auc_interpretation = "–°–ª–∞–±–∞—è"
        
            self.ax4a.text(0.6, 0.2, f'{auc_interpretation} –º–æ–¥–µ–ª—å', 
                        transform=self.ax4a.transAxes, fontsize=12, 
                        bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.7))

            # –ì—Ä–∞—Ñ–∏–∫ 2: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ scores —Å –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
            self.ax4b.clear()
        
            pos_scores = y_scores[y_test == 1]  # –≤–∞—à–∏ –æ—Ü–µ–Ω–∫–∏
            neg_scores = y_scores[y_test == 0]  # —á—É–∂–∏–µ –æ—Ü–µ–Ω–∫–∏
        
            # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã —Å –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é
            self.ax4b.hist(neg_scores, bins=25, alpha=0.6, label=f'–ß—É–∂–∏–µ (n={len(neg_scores)})', 
                        color='red', density=True, edgecolor='darkred')
            self.ax4b.hist(pos_scores, bins=25, alpha=0.6, label=f'–í–∞—à–∏ (n={len(pos_scores)})', 
                        color='green', density=True, edgecolor='darkgreen')
        
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π
            pos_mean, pos_std = np.mean(pos_scores), np.std(pos_scores)
            neg_mean, neg_std = np.mean(neg_scores), np.std(neg_scores)
        
            # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏ –¥–ª—è —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
            self.ax4b.axvline(pos_mean, color='darkgreen', linestyle='-', linewidth=2, 
                            alpha=0.8, label=f'–°—Ä–µ–¥–Ω–µ–µ –≤–∞—à–∏—Ö: {pos_mean:.3f}')
            self.ax4b.axvline(neg_mean, color='darkred', linestyle='-', linewidth=2, 
                            alpha=0.8, label=f'–°—Ä–µ–¥–Ω–µ–µ —á—É–∂–∏—Ö: {neg_mean:.3f}')
        
            # –õ–∏–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
            self.ax4b.axvline(optimal_threshold, color='black', linestyle='--', linewidth=2, 
                            alpha=0.8, label=f'–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {optimal_threshold:.3f}')
        
            # –û–±–ª–∞—Å—Ç–∏ –æ—à–∏–±–æ–∫
            if optimal_threshold < 1.0 and optimal_threshold > 0.0:
                # –û–±–ª–∞—Å—Ç—å False Rejections (–≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞)
                x_fill_fr = np.linspace(min(y_scores), optimal_threshold, 100)
                y_fill_fr = np.histogram(pos_scores, bins=100, range=(min(y_scores), max(y_scores)), density=True)[0]
                x_bins = np.histogram(pos_scores, bins=100, range=(min(y_scores), max(y_scores)))[1]
                mask_fr = x_bins[:-1] <= optimal_threshold
                if np.any(mask_fr):
                    self.ax4b.fill_between(x_bins[:-1][mask_fr], 0, y_fill_fr[mask_fr], 
                                        alpha=0.3, color='orange', label='False Rejections')
            
                # –û–±–ª–∞—Å—Ç—å False Acceptances (—á—É–∂–∏–µ –¥–∞–Ω–Ω—ã–µ –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞)
                mask_fa = x_bins[:-1] >= optimal_threshold
                y_fill_fa = np.histogram(neg_scores, bins=100, range=(min(y_scores), max(y_scores)), density=True)[0]
                if np.any(mask_fa):
                    self.ax4b.fill_between(x_bins[:-1][mask_fa], 0, y_fill_fa[mask_fa], 
                                        alpha=0.3, color='yellow', label='False Acceptances')

            self.ax4b.set_xlabel('–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞')
            self.ax4b.set_ylabel('–ü–ª–æ—Ç–Ω–æ—Å—Ç—å')
            self.ax4b.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞')
            self.ax4b.legend(loc='upper right', fontsize=8)
            self.ax4b.grid(True, alpha=0.3)

            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç–∏
            denominator = np.sqrt((pos_std**2 + neg_std**2) / 2)
            if denominator > 0:
                separation = abs(pos_mean - neg_mean) / denominator
            else:
                separation = abs(pos_mean - neg_mean)
            self.ax4b.text(0.02, 0.98, 
                        f'–†–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç—å: {separation:.2f}\n'
                        f'–ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ: {min(np.max(neg_scores), np.max(pos_scores)) - max(np.min(neg_scores), np.min(pos_scores)):.3f}',
                        transform=self.ax4b.transAxes, fontsize=10, verticalalignment='top',
                        bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow", alpha=0.8))

            self.canvas4.draw()
        
            print(f"ROC AUC: {roc_auc:.3f} ({auc_interpretation})")
            print(f"–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {optimal_threshold:.3f}")
            print(f"–†–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç—å –∫–ª–∞—Å—Å–æ–≤: {separation:.2f}")
        
        except ImportError:
            # sklearn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
            self.ax4a.text(0.5, 0.5, 'scikit-learn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\nROC-–∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω', 
                        ha='center', va='center', transform=self.ax4a.transAxes, fontsize=14)
            self.ax4b.text(0.5, 0.5, '–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ scikit-learn:\npip install scikit-learn', 
                        ha='center', va='center', transform=self.ax4b.transAxes, fontsize=14)
            self.canvas4.draw()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ ROC –∞–Ω–∞–ª–∏–∑–∞: {e}")
            import traceback
            traceback.print_exc()
            self.ax4a.text(0.5, 0.5, f'–û—à–∏–±–∫–∞ ROC –∞–Ω–∞–ª–∏–∑–∞:\n{str(e)}', 
                        ha='center', va='center', transform=self.ax4a.transAxes, fontsize=12)
            self.canvas4.draw()
    
    def load_samples_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤ –≤ —Ç–∞–±–ª–∏—Ü—É"""
        try:
            # –û—á–∏—â–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
            for item in self.samples_tree.get_children():
                self.samples_tree.delete(item)
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥–∞–Ω–Ω—ã–º–∏
            for i, sample in enumerate(self.training_samples, 1):
                if sample.features:
                    self.samples_tree.insert('', 'end', values=(
                        i,
                        sample.timestamp.strftime('%d.%m %H:%M:%S'),
                        f"{sample.features.get('avg_dwell_time', 0)*1000:.1f} –º—Å",
                        f"{sample.features.get('avg_flight_time', 0)*1000:.1f} –º—Å", 
                        f"{sample.features.get('typing_speed', 0):.1f} –∫–ª/—Å",
                        f"{sample.features.get('total_typing_time', 0):.1f} —Å"
                    ))
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–∞–±–ª–∏—Ü—ã: {e}")



    def _generate_realistic_negatives(self, X_positive: np.ndarray, n_samples: int) -> np.ndarray:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –†–ï–ê–õ–ò–°–¢–ò–ß–ù–´–• –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤"""
        print(f"\nüé≠ –°–û–ó–î–ê–ù–ò–ï –†–ï–ê–õ–ò–°–¢–ò–ß–ù–´–• –ò–ú–ò–¢–ê–¢–û–†–û–í")
    
        # –ê–Ω–∞–ª–∏–∑ –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        mean = np.mean(X_positive, axis=0)
        std = np.std(X_positive, axis=0)
    
        print(f"–í–∞—à –ø—Ä–æ—Ñ–∏–ª—å –ø–µ—á–∞—Ç–∏:")
        print(f"  –í—Ä–µ–º—è —É–¥–µ—Ä–∂–∞–Ω–∏—è: {mean[0]*1000:.1f} ¬± {std[0]*1000:.1f} –º—Å")
        print(f"  –í—Ä–µ–º—è –º–µ–∂–¥—É –∫–ª–∞–≤–∏—à–∞–º–∏: {mean[2]*1000:.1f} ¬± {std[2]*1000:.1f} –º—Å")
        print(f"  –°–∫–æ—Ä–æ—Å—Ç—å: {mean[4]:.1f} ¬± {std[4]:.1f} –∫–ª–∞–≤–∏—à/—Å–µ–∫")
    
        realistic_samples = []
    
        # 1. –ü–æ—Ö–æ–∂–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ (30%) - –Ω–µ–±–æ–ª—å—à–∏–µ –æ—Ç–ª–∏—á–∏—è
        similar_count = int(n_samples * 0.3)
        print(f"–°–æ–∑–¥–∞–µ–º {similar_count} –ø–æ—Ö–æ–∂–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π...")
        for i in range(similar_count):
            # –û—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 1.5-3 —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π
            noise_factor = np.random.uniform(1.5, 3.0)
            noise = np.random.normal(0, std * noise_factor)
            sample = mean + noise
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Å–Ω–∏–∑—É –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            sample = np.maximum(sample, mean * 0.1)
            realistic_samples.append(sample)
    
        # 2. –£–º–µ—Ä–µ–Ω–Ω–æ –æ—Ç–ª–∏—á–∞—é—â–∏–µ—Å—è (40%) 
        moderate_count = int(n_samples * 0.4)
        print(f"–°–æ–∑–¥–∞–µ–º {moderate_count} —É–º–µ—Ä–µ–Ω–Ω–æ –æ—Ç–ª–∏—á–∞—é—â–∏—Ö—Å—è...")
        for i in range(moderate_count):
            # –°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç–ª–∏—á–∏—è –≤ —Å—Ç–∏–ª–µ –ø–µ—á–∞—Ç–∏
            factors = np.random.uniform(0.4, 2.5, size=6)  # –∫–∞–∂–¥—ã–π –ø—Ä–∏–∑–Ω–∞–∫ –º–µ–Ω—è–µ—Ç—Å—è –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ
            sample = mean * factors
            # –î–æ–±–∞–≤–ª—è–µ–º —à—É–º
            noise = np.random.normal(0, std * 0.8)
            sample = sample + noise
            sample = np.maximum(sample, mean * 0.05)
            realistic_samples.append(sample)
    
        # 3. –°–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—â–∏–µ—Å—è (30%)
        different_count = n_samples - similar_count - moderate_count
        print(f"–°–æ–∑–¥–∞–µ–º {different_count} —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—â–∏—Ö—Å—è...")
        for i in range(different_count):
            # –ë–æ–ª–µ–µ –¥—Ä–∞–º–∞—Ç–∏—á–Ω—ã–µ, –Ω–æ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –æ—Ç–ª–∏—á–∏—è
            if np.random.random() < 0.5:
                # –ë—ã—Å—Ç—Ä—ã–µ –ø–µ—á–∞—Ç–∞—é—â–∏–µ
                factors = np.array([
                    np.random.uniform(0.2, 0.7),    # –∫–æ—Ä–æ—Ç–∫–æ–µ —É–¥–µ—Ä–∂–∞–Ω–∏–µ
                    np.random.uniform(0.3, 0.8),    # –Ω–∏–∑–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å —É–¥–µ—Ä–∂–∞–Ω–∏—è
                    np.random.uniform(0.1, 0.5),    # –∫–æ—Ä–æ—Ç–∫–∏–µ –ø–∞—É–∑—ã
                    np.random.uniform(0.2, 0.7),    # –Ω–∏–∑–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–∞—É–∑
                    np.random.uniform(1.5, 4.0),    # –≤—ã—Å–æ–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å
                    np.random.uniform(0.3, 0.8)     # –º–µ–Ω—å—à–µ –≤—Ä–µ–º–µ–Ω–∏
                ])
            else:
                # –ú–µ–¥–ª–µ–Ω–Ω—ã–µ –ø–µ—á–∞—Ç–∞—é—â–∏–µ
                factors = np.array([
                    np.random.uniform(1.5, 4.0),    # –¥–æ–ª–≥–æ–µ —É–¥–µ—Ä–∂–∞–Ω–∏–µ
                    np.random.uniform(1.2, 3.0),    # –≤—ã—Å–æ–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å
                    np.random.uniform(2.0, 6.0),    # –¥–æ–ª–≥–∏–µ –ø–∞—É–∑—ã
                    np.random.uniform(1.5, 4.0),    # –≤—ã—Å–æ–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–∞—É–∑
                    np.random.uniform(0.2, 0.7),    # –Ω–∏–∑–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å
                    np.random.uniform(1.5, 4.0)     # –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏
                ])
        
            sample = mean * factors
            noise = np.random.normal(0, std * 0.5)
            sample = sample + noise
            sample = np.maximum(sample, mean * 0.01)
            realistic_samples.append(sample)
    
        result = np.array(realistic_samples)
    
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç—å
        from sklearn.metrics.pairwise import euclidean_distances
        distances = euclidean_distances(result, X_positive)
        min_distances = np.min(distances, axis=1)
    
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤:")
        print(f"  –°–æ–∑–¥–∞–Ω–æ: {len(result)}")
        print(f"  –ú–∏–Ω. —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –≤–∞—à–∏—Ö: {np.min(min_distances):.3f}")
        print(f"  –°—Ä–µ–¥–Ω–µ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {np.mean(min_distances):.3f}")
        print(f"  –ú–∞–∫—Å. —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {np.max(min_distances):.3f}")
    
        return result
    
    def _generate_user_variations(self, X_positive: np.ndarray, n_variations: int) -> np.ndarray:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∞—à–∏—Ö –≤–∞—Ä–∏–∞—Ü–∏–π (–∫–æ–≥–¥–∞ –ø–µ—á–∞—Ç–∞–µ—Ç–µ –ø–æ-—Ä–∞–∑–Ω–æ–º—É)"""
        print(f"\nüë§ –°–û–ó–î–ê–ù–ò–ï –í–ê–®–ò–• –í–ê–†–ò–ê–¶–ò–ô")
    
        mean = np.mean(X_positive, axis=0)
        std = np.std(X_positive, axis=0)
    
        variations = []
    
        for i in range(n_variations):
            # –í–∞—à–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ - –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 2 —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π
            variation_factor = np.random.uniform(0.8, 1.5)  # –Ω–µ–±–æ–ª—å—à–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            noise = np.random.normal(0, std * variation_factor)
        
            # –ò–Ω–æ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è (—É—Å—Ç–∞–ª–æ—Å—Ç—å, —Å–ø–µ—à–∫–∞ –∏ —Ç.–¥.)
            if np.random.random() < 0.3:
                # –≠—Ñ—Ñ–µ–∫—Ç —É—Å—Ç–∞–ª–æ—Å—Ç–∏ - –≤—Å–µ –∑–∞–º–µ–¥–ª—è–µ—Ç—Å—è
                systematic_factor = np.array([1.2, 1.1, 1.3, 1.2, 0.8, 1.25])
            elif np.random.random() < 0.3:
                # –≠—Ñ—Ñ–µ–∫—Ç —Å–ø–µ—à–∫–∏ - –≤—Å–µ —É—Å–∫–æ—Ä—è–µ—Ç—Å—è, –Ω–æ –º–µ–Ω–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ
                systematic_factor = np.array([0.8, 1.3, 0.7, 1.4, 1.3, 0.75])
            else:
                # –û–±—ã—á–Ω—ã–µ –Ω–µ–±–æ–ª—å—à–∏–µ –≤–∞—Ä–∏–∞—Ü–∏–∏
                systematic_factor = np.random.uniform(0.9, 1.1, size=6)
        
            sample = mean * systematic_factor + noise
            sample = np.maximum(sample, mean * 0.1)  # –Ω–µ –¥–∞–µ–º —Å—Ç–∞—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏
            variations.append(sample)
    
        print(f"  –°–æ–∑–¥–∞–Ω–æ –≤–∞—Ä–∏–∞—Ü–∏–π –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {len(variations)}")
        return np.array(variations)
    

    def _plot_realistic_metrics(self, threshold_results, current_far, current_frr, current_eer):
        """–ì—Ä–∞—Ñ–∏–∫ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–π –≥—Ä–∞—Ñ–∏–∫
        self.ax3.clear()
    
        # –ì—Ä–∞—Ñ–∏–∫ 1: –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        metrics = ['FAR', 'FRR', 'EER']
        values = [current_far, current_frr, current_eer]
        colors = ['red', 'blue', 'green']
    
        bars = self.ax3.bar(metrics, values, color=colors, alpha=0.7, edgecolor='black', width=0.6)
        self.ax3.set_ylabel('–ü—Ä–æ—Ü–µ–Ω—Ç (%)')
        self.ax3.set_title('–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏')
        self.ax3.set_ylim(0, max(max(values) * 1.3, 10))
    
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
        for bar, value in zip(bars, values):
            height = bar.get_height()
            self.ax3.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                        f'{value:.1f}%', ha='center', va='bottom', fontweight='bold')
    
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–Ω–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        self.ax3.axhline(y=5, color='orange', linestyle='--', alpha=0.7, label='–•–æ—Ä–æ—à–∏–π —É—Ä–æ–≤–µ–Ω—å (5%)')
        self.ax3.axhline(y=15, color='red', linestyle='--', alpha=0.7, label='–ü—Ä–∏–µ–º–ª–µ–º—ã–π —É—Ä–æ–≤–µ–Ω—å (15%)')
    
        self.ax3.legend(loc='upper right', fontsize=8)
        self.ax3.grid(True, alpha=0.3)
    
        self.canvas3.draw()


    def _get_metrics_interpretation(self, far, frr, eer, accuracy):
        """–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫"""
        interpretations = []
    
        if eer < 5:
            interpretations.append("üèÜ –û–¢–õ–ò–ß–ù–ê–Ø —Å–∏—Å—Ç–µ–º–∞ - –≤—ã—Å–æ–∫–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ —É–¥–æ–±—Å—Ç–≤–æ")
        elif eer < 15:
            interpretations.append("‚úÖ –•–û–†–û–®–ê–Ø —Å–∏—Å—Ç–µ–º–∞ - –ø—Ä–∏–µ–º–ª–µ–º—ã–π –±–∞–ª–∞–Ω—Å")
        elif eer < 25:
            interpretations.append("‚ö†Ô∏è –°–†–ï–î–ù–Ø–Ø —Å–∏—Å—Ç–µ–º–∞ - —Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏")
        else:
            interpretations.append("‚ùå –°–õ–ê–ë–ê–Ø —Å–∏—Å—Ç–µ–º–∞ - –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
    
        if far > 10:
            interpretations.append("üö® –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –ø—Ä–∏–Ω—è—Ç–∏—è –∏–º–∏—Ç–∞—Ç–æ—Ä–æ–≤")
        elif far < 1:
            interpretations.append("üîí –û—Ç–ª–∏—á–Ω–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç –∏–º–∏—Ç–∞—Ç–æ—Ä–æ–≤")
    
        if frr > 20:
            interpretations.append("üò§ –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –ª–µ–≥–∏—Ç–∏–º–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
        elif frr < 10:
            interpretations.append("üëç –•–æ—Ä–æ—à–∞—è –ø—Ä–æ—Ö–æ–¥–∏–º–æ—Å—Ç—å –¥–ª—è –ª–µ–≥–∏—Ç–∏–º–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
    
        return "\n".join(f"‚Ä¢ {interp}" for interp in interpretations)
    

    def _generate_balanced_negatives(self, X_positive: np.ndarray, n_needed: int) -> np.ndarray:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–´–• –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤"""
        print(f"\nüé≠ –°–û–ó–î–ê–ù–ò–ï –°–ë–ê–õ–ê–ù–°–ò–†–û–í–ê–ù–ù–´–• –ò–ú–ò–¢–ê–¢–û–†–û–í")
    
        mean = np.mean(X_positive, axis=0)
        std = np.std(X_positive, axis=0)
    
        # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å
        std = np.maximum(std, mean * 0.1)  # –º–∏–Ω–∏–º—É–º 10% –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ
    
        negatives = []
    
        # 40% - –ë–ª–∏–∑–∫–∏–µ, –Ω–æ –æ—Ç–ª–∏—á–∞—é—â–∏–µ—Å—è
        close_count = int(n_needed * 0.4)
        for i in range(close_count):
            # –ò–∑–º–µ–Ω—è–µ–º 2-3 –ø—Ä–∏–∑–Ω–∞–∫–∞ —É–º–µ—Ä–µ–Ω–Ω–æ
            sample = mean.copy()
            features_to_change = np.random.choice(6, size=np.random.randint(2, 4), replace=False)
        
            for feat_idx in features_to_change:
                # –£–º–µ—Ä–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è: 0.6-1.8x –æ—Ç –≤–∞—à–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ
                factor = np.random.choice([
                    np.random.uniform(0.6, 0.85),   # –º–µ–¥–ª–µ–Ω–Ω–µ–µ
                    np.random.uniform(1.15, 1.8)    # –±—ã—Å—Ç—Ä–µ–µ
                ])
                sample[feat_idx] = mean[feat_idx] * factor
        
            # –ù–µ–±–æ–ª—å—à–æ–π —à—É–º
            noise = np.random.normal(0, std * 0.4)
            sample = sample + noise
            sample = np.maximum(sample, mean * 0.05)
            negatives.append(sample)
    
        # 35% - –£–º–µ—Ä–µ–Ω–Ω–æ –æ—Ç–ª–∏—á–∞—é—â–∏–µ—Å—è
        moderate_count = int(n_needed * 0.35)
        for i in range(moderate_count):
            # –°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç–ª–∏—á–∏—è –≤ —Å—Ç–∏–ª–µ
            if np.random.random() < 0.5:
                # –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∏–ª—å
                factors = np.array([0.5, 0.7, 0.4, 0.6, 1.8, 0.6])
            else:
                # –ú–µ–¥–ª–µ–Ω–Ω—ã–π —Å—Ç–∏–ª—å
                factors = np.array([1.8, 1.5, 2.2, 1.8, 0.5, 2.0])
            
            sample = mean * factors
            noise = np.random.normal(0, std * 0.3)
            sample = sample + noise  
            sample = np.maximum(sample, mean * 0.02)
            negatives.append(sample)
    
        # 25% - –°–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—â–∏–µ—Å—è, –Ω–æ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ
        different_count = n_needed - close_count - moderate_count
        for i in range(different_count):
            # –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ, –Ω–æ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å—Ç–∏–ª–∏
            if np.random.random() < 0.5:
                # –û—á–µ–Ω—å –±—ã—Å—Ç—Ä—ã–µ
                factors = np.array([0.2, 0.4, 0.15, 0.3, 3.5, 0.3])
            else:
                # –û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω—ã–µ
                factors = np.array([3.0, 2.5, 4.0, 3.5, 0.25, 4.0])
            
            sample = mean * factors
            noise = np.random.normal(0, std * 0.2)
            sample = sample + noise
            sample = np.maximum(sample, mean * 0.01)
            negatives.append(sample)
    
        result = np.array(negatives)
        print(f"  –°–æ–∑–¥–∞–Ω–æ {len(result)} —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤")
    
        return result


    def _explain_confidence_calculation(self):
        """–û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–∞—Å—á–µ—Ç–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
        return """–°–∏—Å—Ç–µ–º–∞ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ KNN –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä:

1. –û–°–ù–û–í–ù–û–ô –ú–ï–¢–û–î (KNN):
   ‚Ä¢ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ –≤–∞—à–∏—Ö + —á—É–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö
   ‚Ä¢ –ü—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å 0-100%
   
2. –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó:
   ‚Ä¢ –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –≤–∞—à–∏—Ö –æ–±—É—á–∞—é—â–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤
   ‚Ä¢ –ê–Ω–∞–ª–∏–∑ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
   ‚Ä¢ –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ —Å –≤–µ—Å–∞–º–∏
   
3. –§–ò–ù–ê–õ–¨–ù–ê–Ø –£–í–ï–†–ï–ù–ù–û–°–¢–¨:
   ‚Ä¢ 80%+ = –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–µ –Ω–∞ –≤–∞—à —Å—Ç–∏–ª—å
   ‚Ä¢ 60-80% = –ø–æ—Ö–æ–∂–µ, –Ω–æ –µ—Å—Ç—å –æ—Ç–ª–∏—á–∏—è  
   ‚Ä¢ 40-60% = —Å–æ–º–Ω–∏—Ç–µ–ª—å–Ω–æ
   ‚Ä¢ <40% = —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –Ω–µ –≤—ã"""
    

    def _interpret_results(self, far, frr, eer, separation):
        """–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        interpretations = []
    
        # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
        if eer < 10:
            interpretations.append("üèÜ –û–¢–õ–ò–ß–ù–ê–Ø –±–∏–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞")
        elif eer < 20:
            interpretations.append("‚úÖ –•–û–†–û–®–ê–Ø —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")
        elif eer < 35:
            interpretations.append("‚ö†Ô∏è –ü–†–ò–ï–ú–õ–ï–ú–ê–Ø —Å–∏—Å—Ç–µ–º–∞, –Ω–æ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å")
        else:
            interpretations.append("‚ùå –°–õ–ê–ë–ê–Ø —Å–∏—Å—Ç–µ–º–∞, –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö")
    
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        if far < 5:
            interpretations.append("üîí –í—ã—Å–æ–∫–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç –∏–º–∏—Ç–∞—Ç–æ—Ä–æ–≤")
        elif far < 15:
            interpretations.append("üõ°Ô∏è –ü—Ä–∏–µ–º–ª–µ–º–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç –∏–º–∏—Ç–∞—Ç–æ—Ä–æ–≤")
        else:
            interpretations.append("‚ö†Ô∏è –†–∏—Å–∫ –ø—Ä–∏–Ω—è—Ç–∏—è –∏–º–∏—Ç–∞—Ç–æ—Ä–æ–≤ - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–≤—ã—à–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞")
    
        # –£–¥–æ–±—Å—Ç–≤–æ
        if frr < 10:
            interpretations.append("üëç –û—Ç–ª–∏—á–Ω–∞—è –ø—Ä–æ—Ö–æ–¥–∏–º–æ—Å—Ç—å –¥–ª—è –≤–∞—Å")
        elif frr < 25:
            interpretations.append("‚úÖ –•–æ—Ä–æ—à–∞—è –ø—Ä–æ—Ö–æ–¥–∏–º–æ—Å—Ç—å, —Ä–µ–¥–∫–∏–µ –æ—Ç–∫–∞–∑—ã")
        else:
            interpretations.append("üò§ –ß–∞—Å—Ç—ã–µ –æ—Ç–∫–∞–∑—ã - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–Ω–∏–∂–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞")
    
        # –†–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç—å
        if separation > 0.3:
            interpretations.append("üìä –û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç—å –∫–ª–∞—Å—Å–æ–≤")
        elif separation > 0.15:
            interpretations.append("üìà –•–æ—Ä–æ—à–∞—è —Ä–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç—å –∫–ª–∞—Å—Å–æ–≤")
        else:
            interpretations.append("üìâ –°–ª–∞–±–∞—è —Ä–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç—å - –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
    
        return "\n".join(f"‚Ä¢ {interp}" for interp in interpretations)
    

    def _plot_stable_metrics(self, results_by_threshold, standard_result):
        """–ì—Ä–∞—Ñ–∏–∫ —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        self.ax3.clear()
    
        # –ì—Ä–∞—Ñ–∏–∫ –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –ø—Ä–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º –ø–æ—Ä–æ–≥–µ
        metrics = ['FAR', 'FRR', 'EER']
        values = [standard_result['far'], standard_result['frr'], standard_result['eer']]
        colors = ['red', 'blue', 'green']
    
        bars = self.ax3.bar(metrics, values, color=colors, alpha=0.7, edgecolor='black', width=0.6)
        self.ax3.set_ylabel('–ü—Ä–æ—Ü–µ–Ω—Ç (%)')
        self.ax3.set_title('–ú–µ—Ç—Ä–∏–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (–ø–æ—Ä–æ–≥ 50%)')
        self.ax3.set_ylim(0, max(max(values) * 1.2, 20))
    
        # –ó–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü–∞—Ö
        for bar, value in zip(bars, values):
            height = bar.get_height()
            self.ax3.text(bar.get_x() + bar.get_width()/2., height + 1,
                        f'{value:.1f}%', ha='center', va='bottom', fontweight='bold')
    
        # –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –ª–∏–Ω–∏–∏
        self.ax3.axhline(y=10, color='orange', linestyle='--', alpha=0.7, label='–•–æ—Ä–æ—à–∏–π —É—Ä–æ–≤–µ–Ω—å')
        self.ax3.axhline(y=25, color='red', linestyle='--', alpha=0.7, label='–ü—Ä–∏–µ–º–ª–µ–º—ã–π —É—Ä–æ–≤–µ–Ω—å')
    
        self.ax3.legend(loc='upper right', fontsize=10)
        self.ax3.grid(True, alpha=0.3)
    
        self.canvas3.draw()


    def _generate_normalized_negatives(self, X_positive: np.ndarray, n_needed: int) -> np.ndarray:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ–≥–∞—Ç–∏–≤–æ–≤ –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ"""
        # –í –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ —Å—Ä–µ–¥–Ω–µ–µ ~0, std ~1
    
        negatives = []
    
        # 30% - –±–ª–∏–∑–∫–∏–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã (—Å–ª–æ–∂–Ω—ã–µ –¥–ª—è —Ä–∞–∑–ª–∏—á–µ–Ω–∏—è)
        close_count = int(n_needed * 0.3)
        for i in range(close_count):
            # –ù–µ–±–æ–ª—å—à–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –Ω—É–ª—è
            sample = np.random.normal(0, 0.8, size=6)  # –Ω–µ–º–Ω–æ–≥–æ –±–ª–∏–∂–µ –∫ —Ü–µ–Ω—Ç—Ä—É
            negatives.append(sample)
    
        # 40% - —É–º–µ—Ä–µ–Ω–Ω–æ –æ—Ç–ª–∏—á–∞—é—â–∏–µ—Å—è
        moderate_count = int(n_needed * 0.4)  
        for i in range(moderate_count):
            # –°—Ä–µ–¥–Ω–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
            sample = np.random.normal(0, 1.5, size=6)
            negatives.append(sample)
    
        # 30% - —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—â–∏–µ—Å—è
        far_count = n_needed - close_count - moderate_count
        for i in range(far_count):
            # –ë–æ–ª—å—à–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è  
            sample = np.random.normal(0, 2.5, size=6)
            negatives.append(sample)
    
        return np.array(negatives)
    


    def _interpret_system_quality(self, far, frr, eer, separation):
        """–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∏—Å—Ç–µ–º—ã"""
        quality_notes = []
    
        if eer < 15 and separation > 0.2:
            quality_notes.append("üèÜ –û—Ç–ª–∏—á–Ω–∞—è –±–∏–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞!")
            quality_notes.append("‚úÖ –ì–æ—Ç–æ–≤–∞ –¥–ª—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")
        elif eer < 25:
            quality_notes.append("‚úÖ –•–æ—Ä–æ—à–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å –ø—Ä–∏–µ–º–ª–µ–º—ã–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏")
        else:
            quality_notes.append("‚ö†Ô∏è –°–∏—Å—Ç–µ–º–∞ —Ç—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è")
        
        if far < 10:
            quality_notes.append("üîí –•–æ—Ä–æ—à–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç –∏–º–∏—Ç–∞—Ç–æ—Ä–æ–≤")
        else:
            quality_notes.append("‚ö†Ô∏è –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–≤—ã—à–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
        
        if frr < 20:
            quality_notes.append("üëç –£–¥–æ–±—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–∞ –≤—ã—Å–æ–∫–æ–º —É—Ä–æ–≤–Ω–µ")
        else:
            quality_notes.append("üòÖ –í–æ–∑–º–æ–∂–Ω—ã —á–∞—Å—Ç—ã–µ –æ—Ç–∫–∞–∑—ã - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–Ω–∏–∂–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞")
    
        return "\n".join(f"‚Ä¢ {note}" for note in quality_notes)
    


    def _plot_clean_metrics(self, results_by_threshold, standard_result):
        """–ß–∏—Å—Ç—ã–π –≥—Ä–∞—Ñ–∏–∫ –º–µ—Ç—Ä–∏–∫"""
        self.ax3.clear()
    
        metrics = ['FAR', 'FRR', 'EER']
        values = [standard_result['far'], standard_result['frr'], standard_result['eer']]
        colors = ['red', 'blue', 'green']
    
        bars = self.ax3.bar(metrics, values, color=colors, alpha=0.7, edgecolor='black')
        self.ax3.set_ylabel('–ü—Ä–æ—Ü–µ–Ω—Ç (%)')
        self.ax3.set_title('–ú–µ—Ç—Ä–∏–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã')
        self.ax3.set_ylim(0, max(max(values) * 1.2, 25))
    
        for bar, value in zip(bars, values):
            height = bar.get_height()
            self.ax3.text(bar.get_x() + bar.get_width()/2., height + 1,
                        f'{value:.1f}%', ha='center', va='bottom', fontweight='bold')
    
        self.ax3.axhline(y=10, color='orange', linestyle='--', alpha=0.7, label='–•–æ—Ä–æ—à–∏–π —É—Ä–æ–≤–µ–Ω—å')
        self.ax3.axhline(y=25, color='red', linestyle='--', alpha=0.7, label='–ü—Ä–∏–µ–º–ª–µ–º—ã–π —É—Ä–æ–≤–µ–Ω—å')
    
        self.ax3.legend()
        self.ax3.grid(True, alpha=0.3)
        self.canvas3.draw()



    def _interpret_real_performance(self, all_attempts, successful, failed):
        """–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        success_rate = len(successful) / len(all_attempts) * 100
    
        if success_rate >= 90:
            return "üèÜ –û—Ç–ª–∏—á–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞! –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è."
        elif success_rate >= 80:
            return "‚úÖ –•–æ—Ä–æ—à–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å –≤—ã—Å–æ–∫–æ–π –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å—é."
        elif success_rate >= 70:
            return "üëç –ü—Ä–∏–µ–º–ª–µ–º–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –≤–æ–∑–º–æ–∂–Ω—ã —É–ª—É—á—à–µ–Ω–∏—è."
        elif success_rate >= 60:
            return "‚ö†Ô∏è –°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞."
        else:
            return "‚ùå –ù–∏–∑–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞."
        

    def _get_recommendations(self, attempts, threshold_analysis, recent_success_rate):
        """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é"""
        recommendations = []
    
        current_threshold = attempts[0]['threshold_used'] if attempts else 0.5
        optimal = min(threshold_analysis, key=lambda x: x['eer'])
    
        if abs(optimal['threshold'] - current_threshold) > 0.1:
            if optimal['threshold'] < current_threshold:
                recommendations.append("üîΩ –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–Ω–∏–∂–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ—Ö–æ–¥–∏–º–æ—Å—Ç–∏")
            else:
                recommendations.append("üîº –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–≤—ã—à–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ –¥–ª—è –±–æ–ª—å—à–µ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
    
        if recent_success_rate < 70:
            recommendations.append("üìö –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å —Å –Ω–æ–≤—ã–º–∏ –æ–±—Ä–∞–∑—Ü–∞–º–∏")
            recommendations.append("‚å®Ô∏è –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–µ—á–∞—Ç–∞–µ—Ç–µ –≤ —Ç–æ–º –∂–µ —Å—Ç–∏–ª–µ, —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏")
    
        if len(attempts) < 20:
            recommendations.append("üîÑ –ë–æ–ª—å—à–µ –ø–æ–ø—ã—Ç–æ–∫ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —É–ª—É—á—à–∞—Ç —Ç–æ—á–Ω–æ—Å—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")
    
        confidences = [a['final_confidence'] for a in attempts]
        if np.std(confidences) > 0.25:
            recommendations.append("üìä –í—ã—Å–æ–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ - –≤–æ–∑–º–æ–∂–Ω–æ, —Å—Ç–∏–ª—å –ø–µ—á–∞—Ç–∏ –Ω–µ—Å—Ç–∞–±–∏–ª–µ–Ω")
    
        return "\n".join(f"‚Ä¢ {rec}" for rec in recommendations) if recommendations else "‚Ä¢ –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ!"
    

    def _plot_real_performance(self, attempts, threshold_analysis):
        """–ì—Ä–∞—Ñ–∏–∫ —Ä–µ–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        self.ax3.clear()
    
        # –ì—Ä–∞—Ñ–∏–∫ 1: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        confidences = [a['final_confidence'] for a in attempts]
        results = [a['result'] for a in attempts]
    
        success_conf = [c for c, r in zip(confidences, results) if r]
        fail_conf = [c for c, r in zip(confidences, results) if not r]
    
        if success_conf:
            self.ax3.hist(success_conf, bins=10, alpha=0.7, color='green', 
                        label=f'–£—Å–ø–µ—à–Ω—ã–µ ({len(success_conf)})', density=True)
        if fail_conf:
            self.ax3.hist(fail_conf, bins=10, alpha=0.7, color='red',
                        label=f'–û—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã–µ ({len(fail_conf)})', density=True)
    
        # –¢–µ–∫—É—â–∏–π –ø–æ—Ä–æ–≥
        current_threshold = attempts[0]['threshold_used'] if attempts else 0.5
        self.ax3.axvline(current_threshold, color='black', linestyle='--', 
                        label=f'–¢–µ–∫—É—â–∏–π –ø–æ—Ä–æ–≥ ({current_threshold:.1%})')
    
        self.ax3.set_xlabel('–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã')
        self.ax3.set_ylabel('–ü–ª–æ—Ç–Ω–æ—Å—Ç—å')
        self.ax3.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏')
        self.ax3.legend()
        self.ax3.grid(True, alpha=0.3)
    
        self.canvas3.draw()



    def _interpret_practical_results(self, result, legit_count, suspicious_count):
        """–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        interpretations = []
    
        if result['eer'] < 15:
            interpretations.append("üèÜ –û—Ç–ª–∏—á–Ω–∞—è –±–∏–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —Å–∏—Å—Ç–µ–º–∞!")
        elif result['eer'] < 25:
            interpretations.append("‚úÖ –•–æ—Ä–æ—à–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å –ø—Ä–∏–µ–º–ª–µ–º—ã–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏")
        elif result['eer'] < 40:
            interpretations.append("‚ö†Ô∏è –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ –µ—Å—Ç—å –º–µ—Å—Ç–æ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏–π")
        else:
            interpretations.append("‚ùå –°–∏—Å—Ç–µ–º–∞ —Ç—Ä–µ–±—É–µ—Ç —Å–µ—Ä—å–µ–∑–Ω–æ–π –¥–æ—Ä–∞–±–æ—Ç–∫–∏")

        if result['far'] < 15:
            interpretations.append("üîí –•–æ—Ä–æ—à–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç –∏–º–∏—Ç–∞—Ç–æ—Ä–æ–≤")
        else:
            interpretations.append("‚ö†Ô∏è –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –ø—Ä–∏–Ω—è—Ç–∏—è –∏–º–∏—Ç–∞—Ç–æ—Ä–æ–≤")

        if result['frr'] < 20:
            interpretations.append("üëç –•–æ—Ä–æ—à–∞—è –ø—Ä–æ—Ö–æ–¥–∏–º–æ—Å—Ç—å –¥–ª—è –ª–µ–≥–∏—Ç–∏–º–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
        else:
            interpretations.append("üò§ –ß–∞—Å—Ç—ã–µ –æ—Ç–∫–∞–∑—ã –ª–µ–≥–∏—Ç–∏–º–Ω–æ–º—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é")

        if legit_count < 3:
            interpretations.append("üìä –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ - –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ —É—Å–ø–µ—à–Ω—ã—Ö –≤—Ö–æ–¥–æ–≤")
    
        if suspicious_count < 2:
            interpretations.append("üé≠ –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –æ–± –∏–º–∏—Ç–∞—Ü–∏–∏ - –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–æ–π—Ç–∏ —Å —Ä–∞–∑–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç—å—é")

        return "\n".join(f"‚Ä¢ {interp}" for interp in interpretations)
    

    def _get_practical_recommendations(self, attempts, current_result, optimal_result):
        """–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        recommendations = []
    
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å–±–æ—Ä—É –¥–∞–Ω–Ω—ã—Ö
        legit_attempts = [a for a in attempts if a['final_confidence'] >= 0.7]
        suspicious_attempts = [a for a in attempts if a['final_confidence'] < 0.4]
    
        if len(legit_attempts) < 5:
            recommendations.append("üìà –°–¥–µ–ª–∞–π—Ç–µ –µ—â–µ 3-5 —É—Å–ø–µ—à–Ω—ã—Ö –≤—Ö–æ–¥–æ–≤ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç—å—é –ø–µ—á–∞—Ç–∏")
    
        if len(suspicious_attempts) < 3:
            recommendations.append("üé≠ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–æ–π—Ç–∏ –º–µ–¥–ª–µ–Ω–Ω–æ/–±—ã—Å—Ç—Ä–æ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ '—á—É–∂–æ–≥–æ' —Å—Ç–∏–ª—è")
    
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ
        if abs(optimal_result['threshold'] - 0.75) > 0.1:
            if optimal_result['threshold'] < 0.75:
                recommendations.append(f"üîΩ –ü–æ–Ω–∏–∑—å—Ç–µ –ø–æ—Ä–æ–≥ –¥–æ {optimal_result['threshold']:.0%} –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ—Ö–æ–¥–∏–º–æ—Å—Ç–∏")
            else:
                recommendations.append(f"üîº –ü–æ–≤—ã—Å—å—Ç–µ –ø–æ—Ä–æ–≥ –¥–æ {optimal_result['threshold']:.0%} –¥–ª—è –±–æ–ª—å—à–µ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
    
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
        if current_result['eer'] > 25:
            recommendations.append("üîÑ –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –Ω–æ–≤—ã–º–∏ –æ–±—Ä–∞–∑—Ü–∞–º–∏")
            recommendations.append("‚å®Ô∏è –£–±–µ–¥–∏—Ç–µ—Å—å –≤ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Å—Ç–∏–ª—è –ø–µ—á–∞—Ç–∏")
    
        if len(attempts) < 10:
            recommendations.append("üìä –ë–æ–ª—å—à–µ –ø–æ–ø—ã—Ç–æ–∫ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —É–ª—É—á—à–∞—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –º–µ—Ç—Ä–∏–∫")
    
        return "\n".join(f"‚Ä¢ {rec}" for rec in recommendations) if recommendations else "‚Ä¢ –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ!"
    

    def _plot_practical_metrics(self, threshold_results, current_result, attempts):
        """–ì—Ä–∞—Ñ–∏–∫ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç—Ä–∏–∫"""
        self.ax3.clear()
    
        # –ì—Ä–∞—Ñ–∏–∫ –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
        metrics = ['FAR', 'FRR', 'EER']
        values = [current_result['far'], current_result['frr'], current_result['eer']]
        colors = ['red', 'blue', 'green']
    
        bars = self.ax3.bar(metrics, values, color=colors, alpha=0.7, edgecolor='black')
    
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
        for bar, value in zip(bars, values):
            height = bar.get_height()
            self.ax3.text(bar.get_x() + bar.get_width()/2., height + 1,
                        f'{value:.1f}%', ha='center', va='bottom', fontweight='bold')
    
        self.ax3.set_ylabel('–ü—Ä–æ—Ü–µ–Ω—Ç (%)')
        self.ax3.set_title(f'–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ (–ø–æ—Ä–æ–≥ {current_result["threshold"]:.0%})')
        self.ax3.set_ylim(0, max(max(values) * 1.2, 25))
    
        # –†–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –ª–∏–Ω–∏–∏
        self.ax3.axhline(y=15, color='orange', linestyle='--', alpha=0.7, label='–•–æ—Ä–æ—à–∏–π —É—Ä–æ–≤–µ–Ω—å')
        self.ax3.axhline(y=30, color='red', linestyle='--', alpha=0.7, label='–ü—Ä–∏–µ–º–ª–µ–º—ã–π —É—Ä–æ–≤–µ–Ω—å')
    
        self.ax3.legend()
        self.ax3.grid(True, alpha=0.3)
        self.canvas3.draw()