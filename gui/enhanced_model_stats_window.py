# gui/enhanced_model_stats_window.py - –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ –æ–∫–Ω–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –º–æ–¥–µ–ª–∏

import tkinter as tk
from tkinter import ttk, messagebox
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from matplotlib.backends.backend_tkagg import FigureCanvasTk as FigureCanvas
import numpy as np
from typing import Dict, List, Tuple, Any
from datetime import datetime, timedelta
import json
import os

from models.user import User
from auth.keystroke_auth import KeystrokeAuthenticator
from ml.model_manager import ModelManager
from utils.database import DatabaseManager
from config import FONT_FAMILY, DATA_DIR

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ matplotlib –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å tkinter
plt.style.use('default')

class EnhancedModelStatsWindow:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ –æ–∫–Ω–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –º–æ–¥–µ–ª–∏ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º"""
    
    def __init__(self, parent, user: User, keystroke_auth: KeystrokeAuthenticator):
        self.parent = parent
        self.user = user
        self.keystroke_auth = keystroke_auth
        self.model_manager = ModelManager()
        self.db = DatabaseManager()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –æ–∫–Ω–∞
        self.window = tk.Toplevel(parent)
        self.window.title(f"üìä –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ - {user.username}")
        self.window.geometry("1200x800")
        self.window.resizable(True, True)
        
        # –ú–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ
        self.window.transient(parent)
        self.window.grab_set()
        
        # –î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        self.training_samples = self.db.get_user_training_samples(user.id)
        self.auth_attempts = self.db.get_auth_attempts(user.id, limit=100)
        self.model_info = self.model_manager.get_model_info(user.id)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
        self.create_widgets()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.load_enhanced_statistics()
    
    def create_widgets(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
        header_frame = ttk.Frame(self.window, padding=10)
        header_frame.pack(fill=tk.X)
        
        ttk.Label(
            header_frame,
            text=f"üìä –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏ - {self.user.username}",
            font=(FONT_FAMILY, 16, 'bold')
        ).pack()
        
        # –ë—ã—Å—Ç—Ä–∞—è —Å–≤–æ–¥–∫–∞
        summary_frame = ttk.Frame(header_frame)
        summary_frame.pack(fill=tk.X, pady=10)
        
        self.create_summary_cards(summary_frame)
        
        # Notebook –¥–ª—è –≤–∫–ª–∞–¥–æ–∫
        self.notebook = ttk.Notebook(self.window)
        self.notebook.pack(fill=tk.BOTH, expand=True, padx=10, pady=5)
        
        # –í–∫–ª–∞–¥–∫–∏
        self.create_performance_analysis_tab()
        self.create_temporal_analysis_tab()
        self.create_behavioral_patterns_tab()
        self.create_security_analysis_tab()
        self.create_model_diagnostics_tab()
        self.create_comparison_tab()
        
        # üÜï –ù–û–í–ê–Ø –í–ö–õ–ê–î–ö–ê ROC –ê–ù–ê–õ–ò–ó–ê
        self.create_roc_analysis_tab()

        # –ö–Ω–æ–ø–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π
        self.create_action_buttons()



    
    def create_summary_cards(self, parent):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ä—Ç–æ—á–µ–∫ –±—ã—Å—Ç—Ä–æ–π —Å–≤–æ–¥–∫–∏"""
        cards_frame = ttk.Frame(parent)
        cards_frame.pack(fill=tk.X)
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        model_type = self.model_info.get('model_type', 'none')
        total_samples = len(self.training_samples)
        total_attempts = len(self.auth_attempts)
        
        if self.auth_attempts:
            recent_accuracy = np.mean([a['result'] for a in self.auth_attempts[-10:]])
            avg_confidence = np.mean([a['final_confidence'] for a in self.auth_attempts])
        else:
            recent_accuracy = 0.0
            avg_confidence = 0.0
        
        cards_data = [
            ("üéØ –¢–∏–ø –º–æ–¥–µ–ª–∏", model_type.upper() if model_type != 'none' else '–ù–ï –û–ë–£–ß–ï–ù–ê'),
            ("üìö –û–±—É—á–∞—é—â–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤", f"{total_samples}"),
            ("üîê –ü–æ–ø—ã—Ç–æ–∫ –≤—Ö–æ–¥–∞", f"{total_attempts}"),
            ("üìà –¢–æ—á–Ω–æ—Å—Ç—å (10 –ø–æ–ø—ã—Ç–æ–∫)", f"{recent_accuracy:.1%}"),
            ("üé≤ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{avg_confidence:.1%}")
        ]
        
        for i, (title, value) in enumerate(cards_data):
            card = ttk.LabelFrame(cards_frame, text=title, padding=5)
            card.grid(row=0, column=i, padx=5, sticky='ew')
            cards_frame.columnconfigure(i, weight=1)
            
            ttk.Label(
                card, 
                text=str(value), 
                font=(FONT_FAMILY, 12, 'bold'),
                foreground='darkblue'
            ).pack()
    
    def create_performance_analysis_tab(self):
        """–í–∫–ª–∞–¥–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        frame = ttk.Frame(self.notebook, padding=15)
        self.notebook.add(frame, text="üìà –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
        
        # –í–µ—Ä—Ö–Ω—è—è —á–∞—Å—Ç—å - –º–µ—Ç—Ä–∏–∫–∏
        metrics_frame = ttk.LabelFrame(frame, text="üéØ –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏", padding=10)
        metrics_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.performance_text = tk.Text(metrics_frame, height=8, width=80, font=(FONT_FAMILY, 10))
        perf_scroll = ttk.Scrollbar(metrics_frame, orient=tk.VERTICAL, command=self.performance_text.yview)
        self.performance_text.configure(yscrollcommand=perf_scroll.set)
        
        self.performance_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        perf_scroll.pack(side=tk.RIGHT, fill=tk.Y)
        
        # –ù–∏–∂–Ω—è—è —á–∞—Å—Ç—å - –≥—Ä–∞—Ñ–∏–∫–∏
        chart_frame = ttk.LabelFrame(frame, text="üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏", padding=10)
        chart_frame.pack(fill=tk.BOTH, expand=True)
        
        self.fig_perf, ((self.ax_perf1, self.ax_perf2), (self.ax_perf3, self.ax_perf4)) = plt.subplots(2, 2, figsize=(12, 8))
        self.canvas_perf = FigureCanvasTkAgg(self.fig_perf, chart_frame)
        self.canvas_perf.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    
    def create_temporal_analysis_tab(self):
        """–í–∫–ª–∞–¥–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        frame = ttk.Frame(self.notebook, padding=15)
        self.notebook.add(frame, text="‚è∞ –í—Ä–µ–º–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏–∑")
        
        # –ì—Ä–∞—Ñ–∏–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–µ–Ω–¥–µ–Ω—Ü–∏–π
        self.fig_time, ((self.ax_time1, self.ax_time2), (self.ax_time3, self.ax_time4)) = plt.subplots(2, 2, figsize=(12, 8))
        self.canvas_time = FigureCanvasTkAgg(self.fig_time, frame)
        self.canvas_time.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    
    def create_behavioral_patterns_tab(self):
        """–í–∫–ª–∞–¥–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        frame = ttk.Frame(self.notebook, padding=15)
        self.notebook.add(frame, text="üß† –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã")
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –¥–≤–µ —á–∞—Å—Ç–∏
        left_frame = ttk.Frame(frame)
        left_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(0, 5))
        
        right_frame = ttk.Frame(frame)
        right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True, padx=(5, 0))
        
        # –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (—Ç–µ–∫—Å—Ç)
        patterns_frame = ttk.LabelFrame(left_frame, text="üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã", padding=10)
        patterns_frame.pack(fill=tk.BOTH, expand=True)
        
        self.patterns_text = tk.Text(patterns_frame, height=20, width=50, font=(FONT_FAMILY, 10))
        patterns_scroll = ttk.Scrollbar(patterns_frame, orient=tk.VERTICAL, command=self.patterns_text.yview)
        self.patterns_text.configure(yscrollcommand=patterns_scroll.set)
        
        self.patterns_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        patterns_scroll.pack(side=tk.RIGHT, fill=tk.Y)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        viz_frame = ttk.LabelFrame(right_frame, text="üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤", padding=10)
        viz_frame.pack(fill=tk.BOTH, expand=True)
        
        self.fig_patterns, (self.ax_pat1, self.ax_pat2) = plt.subplots(2, 1, figsize=(8, 8))
        self.canvas_patterns = FigureCanvasTkAgg(self.fig_patterns, viz_frame)
        self.canvas_patterns.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    
    def create_security_analysis_tab(self):
        """–í–∫–ª–∞–¥–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        frame = ttk.Frame(self.notebook, padding=15)
        self.notebook.add(frame, text="üîí –ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
        
        # –ê–Ω–∞–ª–∏–∑ —É–≥—Ä–æ–∑
        threat_frame = ttk.LabelFrame(frame, text="‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ —É–≥—Ä–æ–∑ –∏ –∞–Ω–æ–º–∞–ª–∏–π", padding=10)
        threat_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.security_text = tk.Text(threat_frame, height=8, width=80, font=(FONT_FAMILY, 10))
        sec_scroll = ttk.Scrollbar(threat_frame, orient=tk.VERTICAL, command=self.security_text.yview)
        self.security_text.configure(yscrollcommand=sec_scroll.set)
        
        self.security_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        sec_scroll.pack(side=tk.RIGHT, fill=tk.Y)
        
        # –ì—Ä–∞—Ñ–∏–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        security_chart_frame = ttk.LabelFrame(frame, text="üìä –ú–µ—Ç—Ä–∏–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏", padding=10)
        security_chart_frame.pack(fill=tk.BOTH, expand=True)
        
        self.fig_security, (self.ax_sec1, self.ax_sec2) = plt.subplots(1, 2, figsize=(12, 5))
        self.canvas_security = FigureCanvasTkAgg(self.fig_security, security_chart_frame)
        self.canvas_security.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    
    def create_model_diagnostics_tab(self):
        """–í–∫–ª–∞–¥–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –º–æ–¥–µ–ª–∏"""
        frame = ttk.Frame(self.notebook, padding=15)
        self.notebook.add(frame, text="üîß –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        model_info_frame = ttk.LabelFrame(frame, text="‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏", padding=10)
        model_info_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.model_info_text = tk.Text(model_info_frame, height=10, width=80, font=(FONT_FAMILY, 10))
        model_scroll = ttk.Scrollbar(model_info_frame, orient=tk.VERTICAL, command=self.model_info_text.yview)
        self.model_info_text.configure(yscrollcommand=model_scroll.set)
        
        self.model_info_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        model_scroll.pack(side=tk.RIGHT, fill=tk.Y)
        
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ –≥—Ä–∞—Ñ–∏–∫–∏
        diag_frame = ttk.LabelFrame(frame, text="üìà –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ –≥—Ä–∞—Ñ–∏–∫–∏", padding=10)
        diag_frame.pack(fill=tk.BOTH, expand=True)
        
        self.fig_diag, ((self.ax_diag1, self.ax_diag2), (self.ax_diag3, self.ax_diag4)) = plt.subplots(2, 2, figsize=(12, 8))
        self.canvas_diag = FigureCanvasTkAgg(self.fig_diag, diag_frame)
        self.canvas_diag.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    
    def create_comparison_tab(self):
        """–í–∫–ª–∞–¥–∫–∞ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        frame = ttk.Frame(self.notebook, padding=15)
        self.notebook.add(frame, text="‚öñÔ∏è –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–∞–º–∏
        comparison_frame = ttk.LabelFrame(frame, text="üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º–∏", padding=10)
        comparison_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.comparison_text = tk.Text(comparison_frame, height=8, width=80, font=(FONT_FAMILY, 10))
        comp_scroll = ttk.Scrollbar(comparison_frame, orient=tk.VERTICAL, command=self.comparison_text.yview)
        self.comparison_text.configure(yscrollcommand=comp_scroll.set)
        
        self.comparison_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        comp_scroll.pack(side=tk.RIGHT, fill=tk.Y)
        
        # –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        comp_chart_frame = ttk.LabelFrame(frame, text="üìà –í–∏–∑—É–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ", padding=10)
        comp_chart_frame.pack(fill=tk.BOTH, expand=True)
        
        self.fig_comp, (self.ax_comp1, self.ax_comp2) = plt.subplots(1, 2, figsize=(12, 5))
        self.canvas_comp = FigureCanvasTkAgg(self.fig_comp, comp_chart_frame)
        self.canvas_comp.get_tk_widget().pack(fill=tk.BOTH, expand=True)
    
    def create_action_buttons(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–Ω–æ–ø–æ–∫ –¥–µ–π—Å—Ç–≤–∏–π"""
        buttons_frame = ttk.Frame(self.window)
        buttons_frame.pack(fill=tk.X, padx=10, pady=5)
        
        ttk.Button(
            buttons_frame,
            text="üìÑ –≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞",
            command=self.export_detailed_report
        ).pack(side=tk.LEFT, padx=5)
        
        ttk.Button(
            buttons_frame,
            text="üîÑ –û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ",
            command=self.refresh_data
        ).pack(side=tk.LEFT, padx=5)
        
        ttk.Button(
            buttons_frame,
            text="‚öôÔ∏è –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å",
            command=self.optimize_model
        ).pack(side=tk.LEFT, padx=5)
        
        ttk.Button(
            buttons_frame,
            text="‚ùå –ó–∞–∫—Ä—ã—Ç—å",
            command=self.window.destroy
        ).pack(side=tk.RIGHT, padx=5)
    
    def load_enhanced_statistics(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –≤–∫–ª–∞–¥–∫–∏
            self.load_performance_analysis()
            self.load_temporal_analysis()
            self.load_behavioral_patterns()
            self.load_security_analysis()
            self.load_model_diagnostics()
            self.load_comparison_analysis()

            # üÜï –ù–û–í–´–ô ROC –ê–ù–ê–õ–ò–ó
            self.load_roc_analysis()
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            import traceback
            traceback.print_exc()
    
    def load_performance_analysis(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            if not self.auth_attempts:
                self.performance_text.insert(tk.END, "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n–í—ã–ø–æ–ª–Ω–∏—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–ø—ã—Ç–æ–∫ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏.")
                return
            
            # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
            total_attempts = len(self.auth_attempts)
            successful_attempts = sum(1 for a in self.auth_attempts if a['result'])
            success_rate = successful_attempts / total_attempts * 100 if total_attempts > 0 else 0
            
            avg_confidence = np.mean([a['final_confidence'] for a in self.auth_attempts])
            confidence_std = np.std([a['final_confidence'] for a in self.auth_attempts])
            
            recent_10 = self.auth_attempts[:10]
            recent_success_rate = np.mean([a['result'] for a in recent_10]) * 100 if recent_10 else 0
            
            # FAR/FRR –∞–Ω–∞–ª–∏–∑ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π)
            high_conf_attempts = [a for a in self.auth_attempts if a['final_confidence'] >= 0.7]
            low_conf_attempts = [a for a in self.auth_attempts if a['final_confidence'] < 0.4]
            
            far_estimate = sum(1 for a in low_conf_attempts if a['result']) / len(low_conf_attempts) * 100 if low_conf_attempts else 0
            frr_estimate = sum(1 for a in high_conf_attempts if not a['result']) / len(high_conf_attempts) * 100 if high_conf_attempts else 0
            
            performance_report = f"""–ê–ù–ê–õ–ò–ó –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò –°–ò–°–¢–ï–ú–´
{'='*60}

üìä –û–ë–©–ò–ï –ú–ï–¢–†–ò–ö–ò:
‚Ä¢ –í—Å–µ–≥–æ –ø–æ–ø—ã—Ç–æ–∫ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏: {total_attempts}
‚Ä¢ –£—Å–ø–µ—à–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫: {successful_attempts}
‚Ä¢ –û–±—â–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {success_rate:.1f}%
‚Ä¢ –£—Å–ø–µ—Ö –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –ø–æ–ø—ã—Ç–æ–∫: {recent_success_rate:.1f}%

üéØ –ê–ù–ê–õ–ò–ó –£–í–ï–†–ï–ù–ù–û–°–¢–ò:
‚Ä¢ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence:.3f} ({avg_confidence*100:.1f}%)
‚Ä¢ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {confidence_std:.3f}
‚Ä¢ –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: {'–í–´–°–û–ö–ê–Ø' if confidence_std < 0.2 else '–°–†–ï–î–ù–Ø–Ø' if confidence_std < 0.3 else '–ù–ò–ó–ö–ê–Ø'}

üîí –û–¶–ï–ù–ö–ê –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:
‚Ä¢ –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π FAR: {far_estimate:.1f}%
‚Ä¢ –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π FRR: {frr_estimate:.1f}%
‚Ä¢ –°–æ—Å—Ç–æ—è–Ω–∏–µ: {'–ë–ï–ó–û–ü–ê–°–ù–û' if far_estimate < 10 and frr_estimate < 25 else '–¢–†–ï–ë–£–ï–¢ –í–ù–ò–ú–ê–ù–ò–Ø'}

üìà –¢–ï–ù–î–ï–ù–¶–ò–ò:
‚Ä¢ –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã: {'–°–¢–ê–ë–ò–õ–¨–ù–ê–Ø' if confidence_std < 0.25 else '–ù–ï–°–¢–ê–ë–ò–õ–¨–ù–ê–Ø'}
‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {'–°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ' if success_rate > 80 else '–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ'}

‚è∞ –í–†–ï–ú–ï–ù–ù–´–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò:
‚Ä¢ –ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞: {(self.auth_attempts[0]['timestamp'] - self.auth_attempts[-1]['timestamp']).days if len(self.auth_attempts) > 1 else 0} –¥–Ω–µ–π
‚Ä¢ –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {total_attempts / max(1, (self.auth_attempts[0]['timestamp'] - self.auth_attempts[-1]['timestamp']).days):.1f} –ø–æ–ø—ã—Ç–æ–∫/–¥–µ–Ω—å
"""
            
            self.performance_text.insert(tk.END, performance_report)
            
            # –ì—Ä–∞—Ñ–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            self.plot_performance_charts()
            
        except Exception as e:
            self.performance_text.insert(tk.END, f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
    
    def plot_performance_charts(self):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        if not self.auth_attempts:
            return
        
        try:
            # –ì—Ä–∞—Ñ–∏–∫ 1: –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            self.ax_perf1.clear()
            timestamps = [a['timestamp'] for a in reversed(self.auth_attempts)]
            confidences = [a['final_confidence'] for a in reversed(self.auth_attempts)]
            results = [a['result'] for a in reversed(self.auth_attempts)]
            
            # –¶–≤–µ—Ç–∞ —Ç–æ—á–µ–∫ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            colors = ['green' if r else 'red' for r in results]
            self.ax_perf1.scatter(range(len(confidences)), confidences, c=colors, alpha=0.7)
            self.ax_perf1.plot(range(len(confidences)), confidences, 'b-', alpha=0.3)
            self.ax_perf1.axhline(y=0.75, color='orange', linestyle='--', label='–ü–æ—Ä–æ–≥ (75%)')
            self.ax_perf1.set_xlabel('–ü–æ–ø—ã—Ç–∫–∞')
            self.ax_perf1.set_ylabel('–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å')
            self.ax_perf1.set_title('–î–∏–Ω–∞–º–∏–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã')
            self.ax_perf1.legend()
            self.ax_perf1.grid(True, alpha=0.3)
            
            # –ì—Ä–∞—Ñ–∏–∫ 2: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            self.ax_perf2.clear()
            self.ax_perf2.hist(confidences, bins=15, alpha=0.7, edgecolor='black')
            self.ax_perf2.axvline(np.mean(confidences), color='red', linestyle='--', label=f'–°—Ä–µ–¥–Ω–µ–µ: {np.mean(confidences):.2f}')
            self.ax_perf2.set_xlabel('–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å')
            self.ax_perf2.set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
            self.ax_perf2.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏')
            self.ax_perf2.legend()
            self.ax_perf2.grid(True, alpha=0.3)
            
            # –ì—Ä–∞—Ñ–∏–∫ 3: –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            self.ax_perf3.clear()
            knn_scores = [a['knn_confidence'] for a in self.auth_attempts if 'knn_confidence' in a]
            distance_scores = [a['distance_score'] for a in self.auth_attempts if 'distance_score' in a]
            feature_scores = [a['feature_score'] for a in self.auth_attempts if 'feature_score' in a]
            
            if knn_scores and distance_scores and feature_scores:
                components = ['KNN', 'Distance', 'Features']
                avg_scores = [np.mean(knn_scores), np.mean(distance_scores), np.mean(feature_scores)]
                self.ax_perf3.bar(components, avg_scores, color=['skyblue', 'lightcoral', 'lightgreen'])
                self.ax_perf3.set_ylabel('–°—Ä–µ–¥–Ω–∏–π –≤–∫–ª–∞–¥')
                self.ax_perf3.set_title('–°—Ä–µ–¥–Ω–∏–π –≤–∫–ª–∞–¥ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤')
                self.ax_perf3.grid(True, alpha=0.3)
            
            # –ì—Ä–∞—Ñ–∏–∫ 4: –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
            self.ax_perf4.clear()
            window_size = min(5, len(results))
            if window_size > 1:
                moving_avg = []
                for i in range(window_size, len(results) + 1):
                    window = results[i-window_size:i]
                    moving_avg.append(np.mean(window) * 100)
                
                self.ax_perf4.plot(range(window_size, len(results) + 1), moving_avg, 'g-', linewidth=2)
                self.ax_perf4.set_xlabel('–ü–æ–ø—ã—Ç–∫–∞')
                self.ax_perf4.set_ylabel('–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞ (%)')
                self.ax_perf4.set_title(f'–°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ (–æ–∫–Ω–æ {window_size})')
                self.ax_perf4.grid(True, alpha=0.3)
            
            self.fig_perf.tight_layout()
            self.canvas_perf.draw()
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
    
    def load_temporal_analysis(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            if not self.auth_attempts:
                return
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫
            self.ax_time1.clear()
            hours = [a['timestamp'].hour for a in self.auth_attempts]
            self.ax_time1.hist(hours, bins=24, alpha=0.7, edgecolor='black')
            self.ax_time1.set_xlabel('–ß–∞—Å –¥–Ω—è')
            self.ax_time1.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫')
            self.ax_time1.set_title('–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å—É—Ç–æ–∫')
            self.ax_time1.grid(True, alpha=0.3)
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏
            self.ax_time2.clear()
            weekdays = [a['timestamp'].weekday() for a in self.auth_attempts]
            weekday_names = ['–ü–Ω', '–í—Ç', '–°—Ä', '–ß—Ç', '–ü—Ç', '–°–±', '–í—Å']
            weekday_counts = [weekdays.count(i) for i in range(7)]
            self.ax_time2.bar(weekday_names, weekday_counts)
            self.ax_time2.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫')
            self.ax_time2.set_title('–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏')
            self.ax_time2.grid(True, alpha=0.3)
            
            # –¢—Ä–µ–Ω–¥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            self.ax_time3.clear()
            if len(self.auth_attempts) > 5:
                timestamps = [a['timestamp'] for a in reversed(self.auth_attempts)]
                confidences = [a['final_confidence'] for a in reversed(self.auth_attempts)]
                
                # –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è
                x = np.arange(len(confidences))
                z = np.polyfit(x, confidences, min(2, len(confidences)-1))
                p = np.poly1d(z)
                
                self.ax_time3.scatter(x, confidences, alpha=0.6)
                self.ax_time3.plot(x, p(x), "r--", alpha=0.8, label='–¢—Ä–µ–Ω–¥')
                self.ax_time3.set_xlabel('–í—Ä–µ–º—è (–ø–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä)')
                self.ax_time3.set_ylabel('–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å')
                self.ax_time3.set_title('–¢—Ä–µ–Ω–¥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã')
                self.ax_time3.legend()
                self.ax_time3.grid(True, alpha=0.3)
            
            # –°–µ—Å—Å–∏–æ–Ω–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            self.ax_time4.clear()
            daily_attempts = {}
            for attempt in self.auth_attempts:
                date = attempt['timestamp'].date()
                daily_attempts[date] = daily_attempts.get(date, 0) + 1
            
            if daily_attempts:
                dates = list(daily_attempts.keys())
                counts = list(daily_attempts.values())
                
                self.ax_time4.plot(dates, counts, 'o-')
                self.ax_time4.set_xlabel('–î–∞—Ç–∞')
                self.ax_time4.set_ylabel('–ü–æ–ø—ã—Ç–æ–∫ –≤ –¥–µ–Ω—å')
                self.ax_time4.set_title('–ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å')
                self.ax_time4.tick_params(axis='x', rotation=45)
                self.ax_time4.grid(True, alpha=0.3)
            
            self.fig_time.tight_layout()
            self.canvas_time.draw()
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
    
    def load_behavioral_patterns(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        try:
            patterns_analysis = self.analyze_behavioral_patterns()
            
            self.patterns_text.delete('1.0', tk.END)
            self.patterns_text.insert('1.0', patterns_analysis)
            
            # –ì—Ä–∞—Ñ–∏–∫–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            self.plot_behavioral_patterns()
            
        except Exception as e:
            self.patterns_text.insert(tk.END, f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {e}")
    
    def analyze_behavioral_patterns(self) -> str:
        """–ê–Ω–∞–ª–∏–∑ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if not self.auth_attempts or len(self.training_samples) < 10:
            return "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤."
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        training_features = []
        for sample in self.training_samples:
            if sample.features:
                training_features.append([
                    sample.features.get('avg_dwell_time', 0),
                    sample.features.get('avg_flight_time', 0),
                    sample.features.get('typing_speed', 0),
                    sample.features.get('total_typing_time', 0)
                ])
        
        if not training_features:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."
        
        training_features = np.array(training_features)
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        feature_names = ['–í—Ä–µ–º—è —É–¥–µ—Ä–∂–∞–Ω–∏—è', '–í—Ä–µ–º—è –º–µ–∂–¥—É –∫–ª–∞–≤–∏—à–∞–º–∏', '–°–∫–æ—Ä–æ—Å—Ç—å', '–û–±—â–µ–µ –≤—Ä–µ–º—è']
        stability_analysis = []
        
        for i, name in enumerate(feature_names):
            values = training_features[:, i]
            cv = np.std(values) / np.mean(values) if np.mean(values) > 0 else 0
            
            if cv < 0.15:
                stability = "–û–ß–ï–ù–¨ –°–¢–ê–ë–ò–õ–¨–ù–û"
            elif cv < 0.25:
                stability = "–°–¢–ê–ë–ò–õ–¨–ù–û"
            elif cv < 0.35:
                stability = "–£–ú–ï–†–ï–ù–ù–û"
            else:
                stability = "–ù–ï–°–¢–ê–ë–ò–õ–¨–ù–û"
            
            stability_analysis.append(f"‚Ä¢ {name}: {stability} (CV: {cv:.2f})")
        
        # –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤–æ –≤—Ä–µ–º–µ–Ω–∏
        time_patterns = self.analyze_time_patterns()
        
        # –ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π
        anomaly_analysis = self.detect_anomalies()
        
        analysis = f"""–ê–ù–ê–õ–ò–ó –ü–û–í–ï–î–ï–ù–ß–ï–°–ö–ò–• –ü–ê–¢–¢–ï–†–ù–û–í
{'='*50}

üß¨ –ü–†–û–§–ò–õ–¨ –ö–õ–ê–í–ò–ê–¢–£–†–ù–û–ì–û –ü–û–ß–ï–†–ö–ê:
{chr(10).join(stability_analysis)}

üìä –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò –°–¢–ò–õ–Ø:
‚Ä¢ –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å –ø–µ—á–∞—Ç–∏: {np.mean(training_features[:, 2]):.1f} –∫–ª–∞–≤–∏—à/—Å–µ–∫
‚Ä¢ –í—Ä–µ–º—è —É–¥–µ—Ä–∂–∞–Ω–∏—è –∫–ª–∞–≤–∏—à: {np.mean(training_features[:, 0])*1000:.1f} –º—Å
‚Ä¢ –í—Ä–µ–º—è –º–µ–∂–¥—É –∫–ª–∞–≤–∏—à–∞–º–∏: {np.mean(training_features[:, 1])*1000:.1f} –º—Å
‚Ä¢ –û–±—â–∞—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {np.mean(training_features[:, 3]):.1f} —Å–µ–∫

üïê –í–†–ï–ú–ï–ù–ù–´–ï –ü–ê–¢–¢–ï–†–ù–´:
{time_patterns}

‚ö†Ô∏è –û–ë–ù–ê–†–£–ñ–ï–ù–ù–´–ï –ê–ù–û–ú–ê–õ–ò–ò:
{anomaly_analysis}

üéØ –£–ù–ò–ö–ê–õ–¨–ù–û–°–¢–¨ –ü–†–û–§–ò–õ–Ø:
‚Ä¢ –ò–Ω–¥–µ–∫—Å —Ä–∞–∑–ª–∏—á–∏–º–æ—Å—Ç–∏: {self.calculate_distinctiveness_index():.2f}
‚Ä¢ –°–ª–æ–∂–Ω–æ—Å—Ç—å –∏–º–∏—Ç–∞—Ü–∏–∏: {'–í–´–°–û–ö–ê–Ø' if self.calculate_distinctiveness_index() > 0.3 else '–°–†–ï–î–ù–Ø–Ø' if self.calculate_distinctiveness_index() > 0.15 else '–ù–ò–ó–ö–ê–Ø'}

üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:
{self.generate_behavioral_recommendations()}
"""
        
        return analysis
    
    def analyze_time_patterns(self) -> str:
        """–ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        if not self.auth_attempts:
            return "‚Ä¢ –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"
        
        # –ê–Ω–∞–ª–∏–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        hours = [a['timestamp'].hour for a in self.auth_attempts]
        most_active_hour = max(set(hours), key=hours.count)
        
        # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–∏–æ–¥–∏—á–Ω–æ—Å—Ç–∏
        dates = [a['timestamp'].date() for a in self.auth_attempts]
        unique_dates = len(set(dates))
        avg_attempts_per_day = len(self.auth_attempts) / max(1, unique_dates)
        
        patterns = [
            f"‚Ä¢ –ù–∞–∏–±–æ–ª–µ–µ –∞–∫—Ç–∏–≤–Ω–æ–µ –≤—Ä–µ–º—è: {most_active_hour:02d}:00-{most_active_hour+1:02d}:00",
            f"‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –≤ –¥–µ–Ω—å: {avg_attempts_per_day:.1f}",
            f"‚Ä¢ –î–Ω–µ–π —Å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é: {unique_dates}"
        ]
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–≥—É–ª—è—Ä–Ω–æ—Å—Ç–∏
        if len(self.auth_attempts) > 5:
            time_diffs = []
            for i in range(1, len(self.auth_attempts)):
                diff = (self.auth_attempts[i-1]['timestamp'] - self.auth_attempts[i]['timestamp']).total_seconds() / 3600
                time_diffs.append(diff)
            
            avg_interval = np.mean(time_diffs)
            patterns.append(f"‚Ä¢ –°—Ä–µ–¥–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏: {avg_interval:.1f} —á–∞—Å–æ–≤")
        
        return '\n'.join(patterns)
    
    def detect_anomalies(self) -> str:
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –≤ –ø–æ–≤–µ–¥–µ–Ω–∏–∏"""
        if not self.auth_attempts:
            return "‚Ä¢ –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π"
        
        anomalies = []
        
        # –ê–Ω–æ–º–∞–ª–∏–∏ –≤ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        confidences = [a['final_confidence'] for a in self.auth_attempts]
        mean_conf = np.mean(confidences)
        std_conf = np.std(confidences)
        
        outliers = [c for c in confidences if abs(c - mean_conf) > 2 * std_conf]
        if outliers:
            anomalies.append(f"‚Ä¢ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(outliers)} –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏")
        
        # –ê–Ω–æ–º–∞–ª–∏–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏
        failed_attempts = [a for a in self.auth_attempts if not a['result']]
        if len(failed_attempts) > len(self.auth_attempts) * 0.3:
            anomalies.append(f"‚Ä¢ –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫: {len(failed_attempts)/len(self.auth_attempts)*100:.1f}%")
        
        # –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        low_conf_successful = [a for a in self.auth_attempts if a['result'] and a['final_confidence'] < 0.6]
        if low_conf_successful:
            anomalies.append(f"‚Ä¢ {len(low_conf_successful)} —É—Å–ø–µ—à–Ω—ã—Ö –≤—Ö–æ–¥–æ–≤ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (–≤–æ–∑–º–æ–∂–Ω—ã–µ –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è)")
        
        if not anomalies:
            anomalies.append("‚Ä¢ –ê–Ω–æ–º–∞–ª–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ - –ø–æ–≤–µ–¥–µ–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ")
        
        return '\n'.join(anomalies)
    
    def calculate_distinctiveness_index(self) -> float:
        """–†–∞—Å—á–µ—Ç –∏–Ω–¥–µ–∫—Å–∞ —Ä–∞–∑–ª–∏—á–∏–º–æ—Å—Ç–∏ –ø—Ä–æ—Ñ–∏–ª—è"""
        if len(self.training_samples) < 5:
            return 0.0
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        features = []
        for sample in self.training_samples:
            if sample.features:
                features.append([
                    sample.features.get('avg_dwell_time', 0),
                    sample.features.get('avg_flight_time', 0),
                    sample.features.get('typing_speed', 0)
                ])
        
        if not features:
            return 0.0
        
        features = np.array(features)
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
        cvs = []
        for i in range(features.shape[1]):
            values = features[:, i]
            if np.mean(values) > 0:
                cv = np.std(values) / np.mean(values)
                cvs.append(cv)
        
        # –ò–Ω–¥–µ–∫—Å —Ä–∞–∑–ª–∏—á–∏–º–æ—Å—Ç–∏ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if cvs:
            avg_cv = np.mean(cvs)
            # –ß–µ–º —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, —Ç–µ–º –≤—ã—à–µ —Ä–∞–∑–ª–∏—á–∏–º–æ—Å—Ç—å
            distinctiveness = max(0, 1 - avg_cv * 2)
            return min(1.0, distinctiveness)
        
        return 0.0
    
    def generate_behavioral_recommendations(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –ø–æ–≤–µ–¥–µ–Ω–∏—é"""
        recommendations = []
        
        if len(self.training_samples) < 30:
            recommendations.append("‚Ä¢ –°–æ–±–µ—Ä–∏—Ç–µ –±–æ–ª—å—à–µ –æ–±—É—á–∞—é—â–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏")
        
        if len(self.auth_attempts) > 0:
            success_rate = np.mean([a['result'] for a in self.auth_attempts])
            if success_rate < 0.8:
                recommendations.append("‚Ä¢ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—á–∞—Ç–∞—Ç—å –≤ —Ç–æ–º –∂–µ —Å—Ç–∏–ª–µ, —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏")
        
        distinctiveness = self.calculate_distinctiveness_index()
        if distinctiveness < 0.2:
            recommendations.append("‚Ä¢ –í–∞—à —Å—Ç–∏–ª—å –ø–µ—á–∞—Ç–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –ª–µ–≥–∫–æ –∏–º–∏—Ç–∏—Ä–æ–≤–∞–Ω - –±—É–¥—å—Ç–µ –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã")
        
        if not recommendations:
            recommendations.append("‚Ä¢ –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
        
        return '\n'.join(recommendations)
    
    def plot_behavioral_patterns(self):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        try:
            if not self.training_samples:
                return
            
            # –ì—Ä–∞—Ñ–∏–∫ 1: –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            self.ax_pat1.clear()
            
            features = []
            for sample in self.training_samples:
                if sample.features:
                    features.append([
                        sample.features.get('avg_dwell_time', 0) * 1000,  # –≤ –º—Å
                        sample.features.get('avg_flight_time', 0) * 1000,  # –≤ –º—Å
                    ])
            
            if features:
                features = np.array(features)
                self.ax_pat1.scatter(features[:, 0], features[:, 1], alpha=0.6)
                self.ax_pat1.set_xlabel('–í—Ä–µ–º—è —É–¥–µ—Ä–∂–∞–Ω–∏—è (–º—Å)')
                self.ax_pat1.set_ylabel('–í—Ä–µ–º—è –º–µ–∂–¥—É –∫–ª–∞–≤–∏—à–∞–º–∏ (–º—Å)')
                self.ax_pat1.set_title('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –ø–µ—á–∞—Ç–∏')
                self.ax_pat1.grid(True, alpha=0.3)
            
            # –ì—Ä–∞—Ñ–∏–∫ 2: –≠–≤–æ–ª—é—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            self.ax_pat2.clear()
            
            if len(self.training_samples) > 5:
                speeds = [s.features.get('typing_speed', 0) for s in self.training_samples if s.features]
                if speeds:
                    self.ax_pat2.plot(range(len(speeds)), speeds, 'o-', alpha=0.7)
                    self.ax_pat2.set_xlabel('–ù–æ–º–µ—Ä –æ–±—Ä–∞–∑—Ü–∞')
                    self.ax_pat2.set_ylabel('–°–∫–æ—Ä–æ—Å—Ç—å –ø–µ—á–∞—Ç–∏ (–∫–ª–∞–≤–∏—à/—Å–µ–∫)')
                    self.ax_pat2.set_title('–≠–≤–æ–ª—é—Ü–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø–µ—á–∞—Ç–∏')
                    self.ax_pat2.grid(True, alpha=0.3)
            
            self.fig_patterns.tight_layout()
            self.canvas_patterns.draw()
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {e}")
    
    def load_security_analysis(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        try:
            security_analysis = self.analyze_security_aspects()
            
            self.security_text.delete('1.0', tk.END)
            self.security_text.insert('1.0', security_analysis)
            
            # –ì—Ä–∞—Ñ–∏–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            self.plot_security_charts()
            
        except Exception as e:
            self.security_text.insert(tk.END, f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {e}")
    
    def analyze_security_aspects(self) -> str:
        """–ê–Ω–∞–ª–∏–∑ –∞—Å–ø–µ–∫—Ç–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        if not self.auth_attempts:
            return "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏."
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ–ø—ã—Ç–æ–∫ —Å —Ä–∞–∑–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        high_conf = [a for a in self.auth_attempts if a['final_confidence'] >= 0.8]
        medium_conf = [a for a in self.auth_attempts if 0.4 <= a['final_confidence'] < 0.8]
        low_conf = [a for a in self.auth_attempts if a['final_confidence'] < 0.4]
        
        # –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —É–≥—Ä–æ–∑—ã
        threats = []
        
        # –£—Å–ø–µ—à–Ω—ã–µ –≤—Ö–æ–¥—ã —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        suspicious_success = [a for a in low_conf if a['result']]
        if suspicious_success:
            threats.append(f"‚Ä¢ {len(suspicious_success)} –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö —É—Å–ø–µ—à–Ω—ã—Ö –≤—Ö–æ–¥–æ–≤ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é")
        
        # –ù–µ—É–¥–∞—á–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
        suspicious_failures = [a for a in high_conf if not a['result']]
        if suspicious_failures:
            threats.append(f"‚Ä¢ {len(suspicious_failures)} –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é")
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏
        if len(self.auth_attempts) > 10:
            recent_failures = sum(1 for a in self.auth_attempts[:5] if not a['result'])
            if recent_failures >= 3:
                threats.append("‚Ä¢ –ú–Ω–æ–≥–æ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è")
        
        # –†–∞—Å—á–µ—Ç –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        legitimate_attempts = high_conf  # –°—á–∏—Ç–∞–µ–º –ø–æ–ø—ã—Ç–∫–∏ —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é –ª–µ–≥–∏—Ç–∏–º–Ω—ã–º–∏
        impostor_attempts = low_conf    # –°—á–∏—Ç–∞–µ–º –ø–æ–ø—ã—Ç–∫–∏ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é –∏–º–∏—Ç–∞—Ü–∏–µ–π
        
        far = 0.0
        frr = 0.0
        
        if impostor_attempts:
            false_accepts = sum(1 for a in impostor_attempts if a['result'])
            far = false_accepts / len(impostor_attempts) * 100
        
        if legitimate_attempts:
            false_rejects = sum(1 for a in legitimate_attempts if not a['result'])
            frr = false_rejects / len(legitimate_attempts) * 100
        
        eer = (far + frr) / 2
        
        security_level = "–í–´–°–û–ö–ò–ô" if eer < 15 else "–°–†–ï–î–ù–ò–ô" if eer < 25 else "–ù–ò–ó–ö–ò–ô"
        
        analysis = f"""–ê–ù–ê–õ–ò–ó –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò –°–ò–°–¢–ï–ú–´
{'='*50}

üõ°Ô∏è –û–ë–©–ê–Ø –û–¶–ï–ù–ö–ê –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò: {security_level}

üìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û–ü–´–¢–û–ö –ü–û –£–í–ï–†–ï–ù–ù–û–°–¢–ò:
‚Ä¢ –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (‚â•80%): {len(high_conf)} –ø–æ–ø—ã—Ç–æ–∫
‚Ä¢ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (40-80%): {len(medium_conf)} –ø–æ–ø—ã—Ç–æ–∫  
‚Ä¢ –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (<40%): {len(low_conf)} –ø–æ–ø—ã—Ç–æ–∫

üéØ –ü–†–ò–ë–õ–ò–ó–ò–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–†–ò–ö–ò –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:
‚Ä¢ FAR (False Acceptance Rate): {far:.1f}%
‚Ä¢ FRR (False Rejection Rate): {frr:.1f}%
‚Ä¢ EER (Equal Error Rate): {eer:.1f}%

‚ö†Ô∏è –ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–ï –£–ì–†–û–ó–´:
{chr(10).join(threats) if threats else '‚Ä¢ –°–µ—Ä—å–µ–∑–Ω—ã—Ö —É–≥—Ä–æ–∑ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ'}

üîç –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:
{self.generate_security_recommendations(far, frr, eer)}

üìà –¢–†–ï–ù–î –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò:
{self.analyze_security_trend()}
"""
        
        return analysis
    
    def generate_security_recommendations(self, far: float, frr: float, eer: float) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        recommendations = []
        
        if far > 10:
            recommendations.append("‚Ä¢ –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–≤—ã—à–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
        
        if frr > 25:
            recommendations.append("‚Ä¢ –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–Ω–∏–∂–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –ª–æ–∂–Ω—ã—Ö –æ—Ç–∫–∞–∑–æ–≤")
        
        if eer > 20:
            recommendations.append("‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö")
        
        if len(self.auth_attempts) < 20:
            recommendations.append("‚Ä¢ –°–æ–±–µ—Ä–∏—Ç–µ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–ø—ã—Ç–∫–∞—Ö –≤—Ö–æ–¥–∞ –¥–ª—è —Ç–æ—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
        
        if not recommendations:
            recommendations.append("‚Ä¢ –°–∏—Å—Ç–µ–º–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Ö–æ—Ä–æ—à–∏–π —É—Ä–æ–≤–µ–Ω—å –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
        
        return '\n'.join(recommendations)
    
    def analyze_security_trend(self) -> str:
        """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        if len(self.auth_attempts) < 10:
            return "‚Ä¢ –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–∞"
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ 10 –ø–æ–ø—ã—Ç–æ–∫
        recent_10 = self.auth_attempts[:10]
        previous_10 = self.auth_attempts[10:20] if len(self.auth_attempts) >= 20 else []
        
        recent_success = np.mean([a['result'] for a in recent_10])
        recent_confidence = np.mean([a['final_confidence'] for a in recent_10])
        
        if previous_10:
            previous_success = np.mean([a['result'] for a in previous_10])
            previous_confidence = np.mean([a['final_confidence'] for a in previous_10])
            
            success_trend = "–£–õ–£–ß–®–ê–ï–¢–°–Ø" if recent_success > previous_success else "–£–•–£–î–®–ê–ï–¢–°–Ø" if recent_success < previous_success else "–°–¢–ê–ë–ò–õ–¨–ù–û"
            confidence_trend = "–†–ê–°–¢–ï–¢" if recent_confidence > previous_confidence else "–ü–ê–î–ê–ï–¢" if recent_confidence < previous_confidence else "–°–¢–ê–ë–ò–õ–¨–ù–ê"
            
            return f"‚Ä¢ –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {success_trend} ({recent_success:.1%} vs {previous_success:.1%})\n‚Ä¢ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence_trend} ({recent_confidence:.1%} vs {previous_confidence:.1%})"
        else:
            return f"‚Ä¢ –¢–µ–∫—É—â–∞—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å: {recent_success:.1%}\n‚Ä¢ –¢–µ–∫—É—â–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {recent_confidence:.1%}"
    
    def plot_security_charts(self):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        try:
            if not self.auth_attempts:
                return
            
            # –ì—Ä–∞—Ñ–∏–∫ 1: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —É—Ä–æ–≤–Ω—è–º —Ä–∏—Å–∫–∞
            self.ax_sec1.clear()
            
            confidences = [a['final_confidence'] for a in self.auth_attempts]
            high_risk = sum(1 for c in confidences if c < 0.4)
            medium_risk = sum(1 for c in confidences if 0.4 <= c < 0.7)
            low_risk = sum(1 for c in confidences if c >= 0.7)
            
            sizes = [high_risk, medium_risk, low_risk]
            labels = ['–í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫\n(<40%)', '–°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫\n(40-70%)', '–ù–∏–∑–∫–∏–π —Ä–∏—Å–∫\n(‚â•70%)']
            colors = ['red', 'orange', 'green']
            
            if sum(sizes) > 0:
                wedges, texts, autotexts = self.ax_sec1.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%')
                self.ax_sec1.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ø—ã—Ç–æ–∫ –ø–æ —É—Ä–æ–≤–Ω—é —Ä–∏—Å–∫–∞')
            
            # –ì—Ä–∞—Ñ–∏–∫ 2: –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ç—Ä–µ–Ω–¥ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            self.ax_sec2.clear()
            
            if len(self.auth_attempts) > 5:
                # –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                confidences = [a['final_confidence'] for a in reversed(self.auth_attempts)]
                window_size = min(5, len(confidences))
                
                moving_avg = []
                for i in range(window_size, len(confidences) + 1):
                    window = confidences[i-window_size:i]
                    moving_avg.append(np.mean(window))
                
                x = range(window_size, len(confidences) + 1)
                self.ax_sec2.plot(x, moving_avg, 'b-', linewidth=2, label='–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å')
                self.ax_sec2.axhline(y=0.75, color='red', linestyle='--', label='–ü–æ—Ä–æ–≥ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏')
                self.ax_sec2.fill_between(x, moving_avg, 0.75, where=np.array(moving_avg) >= 0.75, 
                                        color='green', alpha=0.3, label='–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–æ–Ω–∞')
                self.ax_sec2.fill_between(x, moving_avg, 0.75, where=np.array(moving_avg) < 0.75, 
                                        color='red', alpha=0.3, label='–ó–æ–Ω–∞ —Ä–∏—Å–∫–∞')
                
                self.ax_sec2.set_xlabel('–ü–æ–ø—ã—Ç–∫–∞')
                self.ax_sec2.set_ylabel('–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å')
                self.ax_sec2.set_title('–¢—Ä–µ–Ω–¥ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã')
                self.ax_sec2.legend()
                self.ax_sec2.grid(True, alpha=0.3)
            
            self.fig_security.tight_layout()
            self.canvas_security.draw()
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏: {e}")
    
    def load_model_diagnostics(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –º–æ–¥–µ–ª–∏"""
        try:
            model_analysis = self.analyze_model_health()
            
            self.model_info_text.delete('1.0', tk.END)
            self.model_info_text.insert('1.0', model_analysis)
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ –≥—Ä–∞—Ñ–∏–∫–∏
            self.plot_diagnostic_charts()
            
        except Exception as e:
            self.model_info_text.insert(tk.END, f"–û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    
    def analyze_model_health(self) -> str:
        """–ê–Ω–∞–ª–∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥–µ–ª–∏"""
        model_type = self.model_info.get('model_type', 'none')
        
        if model_type == 'none':
            return "–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞. –¢—Ä–µ–±—É–µ—Ç—Å—è —Å–±–æ—Ä –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö."
        
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        training_samples = len(self.training_samples)
        is_trained = self.model_info.get('is_trained', False)
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        data_quality = self.assess_training_data_quality()
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
        performance_analysis = self.assess_model_performance()
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
        improvement_suggestions = self.generate_improvement_suggestions()
        
        analysis = f"""–î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ú–û–î–ï–õ–ò
{'='*50}

ü§ñ –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ú–û–î–ï–õ–ò:
‚Ä¢ –¢–∏–ø –º–æ–¥–µ–ª–∏: {model_type.upper()}
‚Ä¢ –°—Ç–∞—Ç—É—Å: {'–û–ë–£–ß–ï–ù–ê' if is_trained else '–ù–ï –û–ë–£–ß–ï–ù–ê'}
‚Ä¢ –û–±—É—á–∞—é—â–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {training_samples}
‚Ä¢ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {self.format_model_params()}

üìä –ö–ê–ß–ï–°–¢–í–û –û–ë–£–ß–ê–Æ–©–ò–• –î–ê–ù–ù–´–•:
{data_quality}

‚ö° –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ –ú–û–î–ï–õ–ò:
{performance_analysis}

üîß –°–û–°–¢–û–Ø–ù–ò–ï –ú–û–î–ï–õ–ò:
{self.assess_model_condition()}

üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–õ–£–ß–®–ï–ù–ò–Æ:
{improvement_suggestions}

üìà –ò–°–¢–û–†–ò–Ø –û–ë–£–ß–ï–ù–ò–Ø:
{self.get_training_history()}
"""
        
        return analysis
    
    def assess_training_data_quality(self) -> str:
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        if not self.training_samples:
            return "‚Ä¢ –ù–µ—Ç –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"
        
        quality_aspects = []
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
        sample_count = len(self.training_samples)
        if sample_count >= 50:
            quality_aspects.append(f"‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤: –û–¢–õ–ò–ß–ù–û ({sample_count})")
        elif sample_count >= 30:
            quality_aspects.append(f"‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤: –•–û–†–û–®–û ({sample_count})")
        else:
            quality_aspects.append(f"‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤: –ù–ï–î–û–°–¢–ê–¢–û–ß–ù–û ({sample_count})")
        
        # –ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        valid_samples = [s for s in self.training_samples if s.features and all(v != 0 for v in s.features.values())]
        data_validity = len(valid_samples) / len(self.training_samples) * 100
        
        if data_validity >= 95:
            quality_aspects.append(f"‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: –û–¢–õ–ò–ß–ù–û ({data_validity:.1f}% –≤–∞–ª–∏–¥–Ω—ã—Ö)")
        elif data_validity >= 80:
            quality_aspects.append(f"‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: –•–û–†–û–®–û ({data_validity:.1f}% –≤–∞–ª–∏–¥–Ω—ã—Ö)")
        else:
            quality_aspects.append(f"‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö: –ü–õ–û–•–û ({data_validity:.1f}% –≤–∞–ª–∏–¥–Ω—ã—Ö)")
        
        # –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –¥–∞–Ω–Ω—ã—Ö
        if valid_samples:
            features_array = np.array([[
                s.features.get('avg_dwell_time', 0),
                s.features.get('typing_speed', 0)
            ] for s in valid_samples])
            
            diversity = np.mean([np.std(features_array[:, i]) for i in range(features_array.shape[1])])
            
            if diversity > 0.02:
                quality_aspects.append("‚Ä¢ –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –¥–∞–Ω–Ω—ã—Ö: –í–´–°–û–ö–û–ï")
            elif diversity > 0.01:
                quality_aspects.append("‚Ä¢ –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –¥–∞–Ω–Ω—ã—Ö: –°–†–ï–î–ù–ï–ï")
            else:
                quality_aspects.append("‚Ä¢ –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –¥–∞–Ω–Ω—ã—Ö: –ù–ò–ó–ö–û–ï")
        
        return '\n'.join(quality_aspects)
    
    def assess_model_performance(self) -> str:
        """–û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        if not self.auth_attempts:
            return "‚Ä¢ –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –æ –ø–æ–ø—ã—Ç–∫–∞—Ö –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏"
        
        performance_aspects = []
        
        # –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
        success_rate = np.mean([a['result'] for a in self.auth_attempts]) * 100
        if success_rate >= 90:
            performance_aspects.append(f"‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å: –û–¢–õ–ò–ß–ù–û ({success_rate:.1f}%)")
        elif success_rate >= 75:
            performance_aspects.append(f"‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å: –•–û–†–û–®–û ({success_rate:.1f}%)")
        else:
            performance_aspects.append(f"‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å: –ü–õ–û–•–û ({success_rate:.1f}%)")
        
        # –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
        confidences = [a['final_confidence'] for a in self.auth_attempts]
        confidence_std = np.std(confidences)
        
        if confidence_std < 0.15:
            performance_aspects.append(f"‚Ä¢ –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: –í–´–°–û–ö–ê–Ø (œÉ={confidence_std:.3f})")
        elif confidence_std < 0.25:
            performance_aspects.append(f"‚Ä¢ –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: –°–†–ï–î–ù–Ø–Ø (œÉ={confidence_std:.3f})")
        else:
            performance_aspects.append(f"‚Ä¢ –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: –ù–ò–ó–ö–ê–Ø (œÉ={confidence_std:.3f})")
        
        # –í—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ (—Å–∏–º—É–ª—è—Ü–∏—è)
        avg_response_time = np.random.uniform(0.05, 0.15)  # –°–∏–º—É–ª—è—Ü–∏—è
        performance_aspects.append(f"‚Ä¢ –í—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞: ~{avg_response_time:.3f} —Å–µ–∫")
        
        return '\n'.join(performance_aspects)
    
    def assess_model_condition(self) -> str:
        """–û—Ü–µ–Ω–∫–∞ –æ–±—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥–µ–ª–∏"""
        if not self.training_samples:
            return "‚Ä¢ –ú–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç –æ–±—É—á–µ–Ω–∏—è"
        
        age_days = (datetime.now() - max(s.timestamp for s in self.training_samples)).days
        
        conditions = []
        
        if age_days > 90:
            conditions.append(f"‚Ä¢ –í–æ–∑—Ä–∞—Å—Ç –º–æ–¥–µ–ª–∏: {age_days} –¥–Ω–µ–π - –¢–†–ï–ë–£–ï–¢ –û–ë–ù–û–í–õ–ï–ù–ò–Ø")
        elif age_days > 30:
            conditions.append(f"‚Ä¢ –í–æ–∑—Ä–∞—Å—Ç –º–æ–¥–µ–ª–∏: {age_days} –¥–Ω–µ–π - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ")
        else:
            conditions.append(f"‚Ä¢ –í–æ–∑—Ä–∞—Å—Ç –º–æ–¥–µ–ª–∏: {age_days} –¥–Ω–µ–π - –∞–∫—Ç—É–∞–ª—å–Ω–∞—è")
        
        # –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
        model_size = len(self.training_samples) * 6 * 8  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –±–∞–π—Ç
        conditions.append(f"‚Ä¢ –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: ~{model_size/1024:.1f} –ö–ë")
        
        # –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç—å
        attempts_per_day = len(self.auth_attempts) / max(1, age_days)
        if attempts_per_day > 10:
            conditions.append("‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç—å: –í–´–°–û–ö–ê–Ø")
        elif attempts_per_day > 3:
            conditions.append("‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç—å: –°–†–ï–î–ù–Ø–Ø")
        else:
            conditions.append("‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç—å: –ù–ò–ó–ö–ê–Ø")
        
        return '\n'.join(conditions)
    
    def format_model_params(self) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏"""
        if 'best_params' in self.model_info:
            params = self.model_info['best_params']
            if params:
                return f"K={params.get('n_neighbors', 'N/A')}, –≤–µ—Å–∞={params.get('weights', 'N/A')}"
        return "–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é"
    
    def generate_improvement_suggestions(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é"""
        suggestions = []
        
        # –ê–Ω–∞–ª–∏–∑ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
        sample_count = len(self.training_samples)
        if sample_count < 30:
            suggestions.append("‚Ä¢ –°–æ–±–µ—Ä–∏—Ç–µ –±–æ–ª—å—à–µ –æ–±—É—á–∞—é—â–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 50+)")
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if self.auth_attempts:
            success_rate = np.mean([a['result'] for a in self.auth_attempts])
            if success_rate < 0.8:
                suggestions.append("‚Ä¢ –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
        
        # –ê–Ω–∞–ª–∏–∑ –≤–æ–∑—Ä–∞—Å—Ç–∞ –º–æ–¥–µ–ª–∏
        if self.training_samples:
            age_days = (datetime.now() - max(s.timestamp for s in self.training_samples)).days
            if age_days > 60:
                suggestions.append("‚Ä¢ –û–±–Ω–æ–≤–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–æ–≤—ã–º–∏ –æ–±—Ä–∞–∑—Ü–∞–º–∏")
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        if self.auth_attempts:
            confidences = [a['final_confidence'] for a in self.auth_attempts]
            if np.std(confidences) > 0.25:
                suggestions.append("‚Ä¢ –†–∞–±–æ—Ç–∞–π—Ç–µ –Ω–∞–¥ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å—é —Å—Ç–∏–ª—è –ø–µ—á–∞—Ç–∏")
        
        if not suggestions:
            suggestions.append("‚Ä¢ –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
        
        return '\n'.join(suggestions)
    
    def get_training_history(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è"""
        if not self.training_samples:
            return "‚Ä¢ –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–Ω—è–º
        training_dates = {}
        for sample in self.training_samples:
            date = sample.timestamp.date()
            training_dates[date] = training_dates.get(date, 0) + 1
        
        history = []
        for date, count in sorted(training_dates.items()):
            history.append(f"‚Ä¢ {date}: {count} –æ–±—Ä–∞–∑—Ü–æ–≤")
        
        if len(history) > 5:
            history = history[:3] + [f"‚Ä¢ ... –∏ –µ—â–µ {len(history)-3} –¥–Ω–µ–π"] + history[-2:]
        
        return '\n'.join(history)
    
    def plot_diagnostic_charts(self):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤"""
        try:
            # –ì—Ä–∞—Ñ–∏–∫ 1: –ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            self.ax_diag1.clear()
            
            if self.training_samples:
                feature_quality = []
                feature_names = ['Dwell Time', 'Flight Time', 'Speed', 'Total Time']
                
                for i, name in enumerate(feature_names):
                    valid_count = 0
                    total_count = len(self.training_samples)
                    
                    for sample in self.training_samples:
                        if sample.features:
                            feature_keys = ['avg_dwell_time', 'avg_flight_time', 'typing_speed', 'total_typing_time']
                            if i < len(feature_keys) and sample.features.get(feature_keys[i], 0) > 0:
                                valid_count += 1
                    
                    quality = valid_count / total_count * 100 if total_count > 0 else 0
                    feature_quality.append(quality)
                
                bars = self.ax_diag1.bar(feature_names, feature_quality, 
                                       color=['green' if q >= 90 else 'orange' if q >= 70 else 'red' for q in feature_quality])
                self.ax_diag1.set_ylabel('–ö–∞—á–µ—Å—Ç–≤–æ (%)')
                self.ax_diag1.set_title('–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤')
                self.ax_diag1.set_ylim(0, 100)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
                for bar, quality in zip(bars, feature_quality):
                    height = bar.get_height()
                    self.ax_diag1.text(bar.get_x() + bar.get_width()/2., height + 1,
                                     f'{quality:.1f}%', ha='center', va='bottom')
            
            # –ì—Ä–∞—Ñ–∏–∫ 2: –¢—Ä–µ–Ω–¥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            self.ax_diag2.clear()
            
            if self.auth_attempts and len(self.auth_attempts) > 5:
                # –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
                results = [a['result'] for a in reversed(self.auth_attempts)]
                window_size = min(5, len(results))
                
                moving_avg = []
                for i in range(window_size, len(results) + 1):
                    window = results[i-window_size:i]
                    moving_avg.append(np.mean(window) * 100)
                
                x = range(window_size, len(results) + 1)
                self.ax_diag2.plot(x, moving_avg, 'b-', linewidth=2)
                self.ax_diag2.fill_between(x, moving_avg, alpha=0.3)
                self.ax_diag2.set_xlabel('–ü–æ–ø—ã—Ç–∫–∞')
                self.ax_diag2.set_ylabel('–£—Å–ø–µ—à–Ω–æ—Å—Ç—å (%)')
                self.ax_diag2.set_title('–¢—Ä–µ–Ω–¥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏')
                self.ax_diag2.grid(True, alpha=0.3)
            
            # –ì—Ä–∞—Ñ–∏–∫ 3: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—É—á–µ–Ω–∏—è
            self.ax_diag3.clear()
            
            if self.training_samples:
                training_dates = [s.timestamp.date() for s in self.training_samples]
                unique_dates = sorted(set(training_dates))
                
                if len(unique_dates) > 1:
                    daily_counts = [training_dates.count(date) for date in unique_dates]
                    self.ax_diag3.plot(unique_dates, daily_counts, 'o-')
                    self.ax_diag3.set_xlabel('–î–∞—Ç–∞')
                    self.ax_diag3.set_ylabel('–û–±—Ä–∞–∑—Ü–æ–≤ –≤ –¥–µ–Ω—å')
                    self.ax_diag3.set_title('–ò—Å—Ç–æ—Ä–∏—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö')
                    self.ax_diag3.tick_params(axis='x', rotation=45)
            
            # –ì—Ä–∞—Ñ–∏–∫ 4: –°–æ—Å—Ç–æ—è–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –º–æ–¥–µ–ª–∏
            self.ax_diag4.clear()
            
            if self.auth_attempts:
                # –ê–Ω–∞–ª–∏–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                knn_scores = [a.get('knn_confidence', 0) for a in self.auth_attempts if 'knn_confidence' in a]
                distance_scores = [a.get('distance_score', 0) for a in self.auth_attempts if 'distance_score' in a]
                feature_scores = [a.get('feature_score', 0) for a in self.auth_attempts if 'feature_score' in a]
                
                if knn_scores and distance_scores and feature_scores:
                    components = ['KNN', 'Distance', 'Features']
                    avg_scores = [np.mean(knn_scores), np.mean(distance_scores), np.mean(feature_scores)]
                    std_scores = [np.std(knn_scores), np.std(distance_scores), np.std(feature_scores)]
                    
                    bars = self.ax_diag4.bar(components, avg_scores, yerr=std_scores, capsize=5)
                    self.ax_diag4.set_ylabel('–°—Ä–µ–¥–Ω–∏–π –≤–∫–ª–∞–¥')
                    self.ax_diag4.set_title('–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤')
                    self.ax_diag4.grid(True, alpha=0.3)
            
            self.fig_diag.tight_layout()
            self.canvas_diag.draw()
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤: {e}")
    
    def load_comparison_analysis(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            comparison_analysis = self.generate_comparison_analysis()
            
            self.comparison_text.delete('1.0', tk.END)
            self.comparison_text.insert('1.0', comparison_analysis)
            
            # –ì—Ä–∞—Ñ–∏–∫–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            self.plot_comparison_charts()
            
        except Exception as e:
            self.comparison_text.insert(tk.END, f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
    
    def generate_comparison_analysis(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        # –≠—Ç–∞–ª–æ–Ω–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –¥–ª—è –±–∏–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö —Å–∏—Å—Ç–µ–º
        benchmarks = {
            'commercial': {'far': 1.0, 'frr': 5.0, 'eer': 3.0},
            'research': {'far': 5.0, 'frr': 15.0, 'eer': 10.0},
            'acceptable': {'far': 10.0, 'frr': 25.0, 'eer': 15.0}
        }
        
        # –†–∞—Å—á–µ—Ç –Ω–∞—à–∏—Ö –º–µ—Ç—Ä–∏–∫
        our_metrics = self.calculate_our_metrics()
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–∞–º–∏
        comparison_results = {}
        for level, benchmark in benchmarks.items():
            comparison_results[level] = {
                'far_diff': our_metrics['far'] - benchmark['far'],
                'frr_diff': our_metrics['frr'] - benchmark['frr'],
                'eer_diff': our_metrics['eer'] - benchmark['eer']
            }
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–∏—Å—Ç–µ–º—ã
        system_category = self.determine_system_category(our_metrics, benchmarks)
        
        analysis = f"""–°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –° –≠–¢–ê–õ–û–ù–ê–ú–ò
{'='*50}

üéØ –ù–ê–®–ò –ü–û–ö–ê–ó–ê–¢–ï–õ–ò:
‚Ä¢ FAR (False Acceptance Rate): {our_metrics['far']:.1f}%
‚Ä¢ FRR (False Rejection Rate): {our_metrics['frr']:.1f}%
‚Ä¢ EER (Equal Error Rate): {our_metrics['eer']:.1f}%

üìä –°–†–ê–í–ù–ï–ù–ò–ï –° –≠–¢–ê–õ–û–ù–ù–´–ú–ò –ü–û–ö–ê–ó–ê–¢–ï–õ–Ø–ú–ò:

üèÜ –ö–û–ú–ú–ï–†–ß–ï–°–ö–ò–ô –£–†–û–í–ï–ù–¨ (FAR‚â§1%, FRR‚â§5%, EER‚â§3%):
‚Ä¢ FAR: {our_metrics['far']:.1f}% vs 1.0% ({'+' if comparison_results['commercial']['far_diff'] >= 0 else ''}{comparison_results['commercial']['far_diff']:.1f}%)
‚Ä¢ FRR: {our_metrics['frr']:.1f}% vs 5.0% ({'+' if comparison_results['commercial']['frr_diff'] >= 0 else ''}{comparison_results['commercial']['frr_diff']:.1f}%)
‚Ä¢ EER: {our_metrics['eer']:.1f}% vs 3.0% ({'+' if comparison_results['commercial']['eer_diff'] >= 0 else ''}{comparison_results['commercial']['eer_diff']:.1f}%)

üî¨ –ò–°–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–°–ö–ò–ô –£–†–û–í–ï–ù–¨ (FAR‚â§5%, FRR‚â§15%, EER‚â§10%):
‚Ä¢ FAR: {our_metrics['far']:.1f}% vs 5.0% ({'+' if comparison_results['research']['far_diff'] >= 0 else ''}{comparison_results['research']['far_diff']:.1f}%)
‚Ä¢ FRR: {our_metrics['frr']:.1f}% vs 15.0% ({'+' if comparison_results['research']['frr_diff'] >= 0 else ''}{comparison_results['research']['frr_diff']:.1f}%)
‚Ä¢ EER: {our_metrics['eer']:.1f}% vs 10.0% ({'+' if comparison_results['research']['eer_diff'] >= 0 else ''}{comparison_results['research']['eer_diff']:.1f}%)

‚úÖ –ü–†–ò–ï–ú–õ–ï–ú–´–ô –£–†–û–í–ï–ù–¨ (FAR‚â§10%, FRR‚â§25%, EER‚â§15%):
‚Ä¢ FAR: {our_metrics['far']:.1f}% vs 10.0% ({'+' if comparison_results['acceptable']['far_diff'] >= 0 else ''}{comparison_results['acceptable']['far_diff']:.1f}%)
‚Ä¢ FRR: {our_metrics['frr']:.1f}% vs 25.0% ({'+' if comparison_results['acceptable']['frr_diff'] >= 0 else ''}{comparison_results['acceptable']['frr_diff']:.1f}%)
‚Ä¢ EER: {our_metrics['eer']:.1f}% vs 15.0% ({'+' if comparison_results['acceptable']['eer_diff'] >= 0 else ''}{comparison_results['acceptable']['eer_diff']:.1f}%)

üèÖ –ö–ê–¢–ï–ì–û–†–ò–Ø –°–ò–°–¢–ï–ú–´: {system_category}

üåü –î–û–°–¢–ò–ñ–ï–ù–ò–Ø:
{self.list_achievements(our_metrics, benchmarks)}

üìà –û–ë–õ–ê–°–¢–ò –î–õ–Ø –£–õ–£–ß–®–ï–ù–ò–Ø:
{self.list_improvement_areas(our_metrics, benchmarks)}

üéì –ü–†–ò–ì–û–î–ù–û–°–¢–¨ –î–õ–Ø –î–ò–ü–õ–û–ú–ù–û–ô –†–ê–ë–û–¢–´:
{self.assess_thesis_suitability(our_metrics, system_category)}
"""
        
        return analysis
    
    def calculate_our_metrics(self) -> dict:
        """–†–∞—Å—á–µ—Ç –Ω–∞—à–∏—Ö –º–µ—Ç—Ä–∏–∫"""
        if not self.auth_attempts:
            return {'far': 0.0, 'frr': 0.0, 'eer': 0.0}
        
        # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        high_conf = [a for a in self.auth_attempts if a['final_confidence'] >= 0.7]
        low_conf = [a for a in self.auth_attempts if a['final_confidence'] < 0.4]
        
        # FAR - –ª–æ–∂–Ω—ã–µ –ø—Ä–∏–Ω—è—Ç–∏—è (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –Ω–æ –ø—Ä–∏–Ω—è—Ç–æ)
        far = 0.0
        if low_conf:
            false_accepts = sum(1 for a in low_conf if a['result'])
            far = false_accepts / len(low_conf) * 100
        
        # FRR - –ª–æ–∂–Ω—ã–µ –æ—Ç–∫–∞–∑—ã (–≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –Ω–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–æ)
        frr = 0.0
        if high_conf:
            false_rejects = sum(1 for a in high_conf if not a['result'])
            frr = false_rejects / len(high_conf) * 100
        
        # EER - –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–∞–≤–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –æ—à–∏–±–æ–∫
        eer = (far + frr) / 2
        
        return {'far': far, 'frr': frr, 'eer': eer}
    
    def determine_system_category(self, our_metrics: dict, benchmarks: dict) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–∏—Å—Ç–µ–º—ã"""
        far, frr, eer = our_metrics['far'], our_metrics['frr'], our_metrics['eer']
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ —É—Ä–æ–≤–Ω—è
        if (far <= benchmarks['commercial']['far'] and 
            frr <= benchmarks['commercial']['frr'] and 
            eer <= benchmarks['commercial']['eer']):
            return "üèÜ –ö–û–ú–ú–ï–†–ß–ï–°–ö–ò–ô –£–†–û–í–ï–ù–¨ - –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ!"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ —É—Ä–æ–≤–Ω—è
        elif (far <= benchmarks['research']['far'] and 
              frr <= benchmarks['research']['frr'] and 
              eer <= benchmarks['research']['eer']):
            return "üî¨ –ò–°–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–°–ö–ò–ô –£–†–û–í–ï–ù–¨ - –û—Ç–ª–∏—á–Ω–æ –¥–ª—è –Ω–∞—É—á–Ω–æ–π —Ä–∞–±–æ—Ç—ã!"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏–µ–º–ª–µ–º–æ–≥–æ —É—Ä–æ–≤–Ω—è
        elif (far <= benchmarks['acceptable']['far'] and 
              frr <= benchmarks['acceptable']['frr'] and 
              eer <= benchmarks['acceptable']['eer']):
            return "‚úÖ –ü–†–ò–ï–ú–õ–ï–ú–´–ô –£–†–û–í–ï–ù–¨ - –•–æ—Ä–æ—à–æ –¥–ª—è –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã!"
        
        else:
            return "‚ö†Ô∏è –¢–†–ï–ë–£–ï–¢ –£–õ–£–ß–®–ï–ù–ò–Ø - –ù–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏"
    
    def list_achievements(self, our_metrics: dict, benchmarks: dict) -> str:
        """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–π"""
        achievements = []
        
        if our_metrics['far'] <= benchmarks['research']['far']:
            achievements.append("‚Ä¢ –ù–∏–∑–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –ª–æ–∂–Ω—ã—Ö –ø—Ä–∏–Ω—è—Ç–∏–π (—Ö–æ—Ä–æ—à–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å)")
        
        if our_metrics['frr'] <= benchmarks['research']['frr']:
            achievements.append("‚Ä¢ –ù–∏–∑–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –ª–æ–∂–Ω—ã—Ö –æ—Ç–∫–∞–∑–æ–≤ (—Ö–æ—Ä–æ—à–µ–µ —É–¥–æ–±—Å—Ç–≤–æ)")
        
        if our_metrics['eer'] <= benchmarks['research']['eer']:
            achievements.append("‚Ä¢ EER —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º")
        
        if len(self.training_samples) >= 50:
            achievements.append("‚Ä¢ –î–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –æ–±—ä–µ–º –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
        
        if len(self.auth_attempts) >= 20:
            achievements.append("‚Ä¢ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
        
        if not achievements:
            achievements.append("‚Ä¢ –°–∏—Å—Ç–µ–º–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä—É–µ—Ç –∏ —Å–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        return '\n'.join(achievements)
    
    def list_improvement_areas(self, our_metrics: dict, benchmarks: dict) -> str:
        """–û–±–ª–∞—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è"""
        improvements = []
        
        if our_metrics['far'] > benchmarks['research']['far']:
            improvements.append("‚Ä¢ –°–Ω–∏–∑–∏—Ç—å FAR - –ø–æ–≤—ã—Å–∏—Ç—å –ø–æ—Ä–æ–≥ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–ª–∏ —É–ª—É—á—à–∏—Ç—å –º–æ–¥–µ–ª—å")
        
        if our_metrics['frr'] > benchmarks['research']['frr']:
            improvements.append("‚Ä¢ –°–Ω–∏–∑–∏—Ç—å FRR - –ø–æ–Ω–∏–∑–∏—Ç—å –ø–æ—Ä–æ–≥ –∏–ª–∏ —Å–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
        
        if our_metrics['eer'] > benchmarks['research']['eer']:
            improvements.append("‚Ä¢ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å EER - —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞—Ç—å FAR –∏ FRR")
        
        if len(self.training_samples) < 50:
            improvements.append("‚Ä¢ –°–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –æ–±—É—á–∞—é—â–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤")
        
        if len(self.auth_attempts) < 30:
            improvements.append("‚Ä¢ –ü—Ä–æ–≤–µ—Å—Ç–∏ –±–æ–ª—å—à–µ —Ç–µ—Å—Ç–æ–≤ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏")
        
        if not improvements:
            improvements.append("‚Ä¢ –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ –≤ —Ç–µ–∫—É—â–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏")
        
        return '\n'.join(improvements)
    
    def assess_thesis_suitability(self, our_metrics: dict, category: str) -> str:
        """–û—Ü–µ–Ω–∫–∞ –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã"""
        suitability = []
        
        if "–ö–û–ú–ú–ï–†–ß–ï–°–ö–ò–ô" in category or "–ò–°–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–°–ö–ò–ô" in category:
            suitability.append("‚úÖ –û–¢–õ–ò–ß–ù–û –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã")
            suitability.append("‚Ä¢ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º")
            suitability.append("‚Ä¢ –ú–æ–∂–Ω–æ —Å–º–µ–ª–æ –≤–∫–ª—é—á–∞—Ç—å –≤ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫—É—é –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫—É—é —á–∞—Å—Ç–∏")
        elif "–ü–†–ò–ï–ú–õ–ï–ú–´–ô" in category:
            suitability.append("‚úÖ –•–û–†–û–®–û –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã")
            suitability.append("‚Ä¢ –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ –±–∏–æ–º–µ—Ç—Ä–∏–∏")
            suitability.append("‚Ä¢ –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –∫–æ–Ω—Ü–µ–ø—Ü–∏–π")
        else:
            suitability.append("‚ö†Ô∏è –£–°–õ–û–í–ù–û –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã")
            suitability.append("‚Ä¢ –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏–µ –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏")
            suitability.append("‚Ä¢ –¢—Ä–µ–±—É–µ—Ç –æ–±—Å—É–∂–¥–µ–Ω–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –∏ –ø—É—Ç–µ–π —É–ª—É—á—à–µ–Ω–∏—è")
        
        suitability.append("")
        suitability.append("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –¥–∏–ø–ª–æ–º–∞:")
        suitability.append("‚Ä¢ –í–∫–ª—é—á–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫")
        suitability.append("‚Ä¢ –û–±—Å—É–¥–∏—Ç–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º–∏")
        suitability.append("‚Ä¢ –ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –ø—É—Ç–∏ —É–ª—É—á—à–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã")
        
        return '\n'.join(suitability)
    
    def plot_comparison_charts(self):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        try:
            # –ì—Ä–∞—Ñ–∏–∫ 1: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–∞–º–∏
            self.ax_comp1.clear()
            
            our_metrics = self.calculate_our_metrics()
            
            metrics = ['FAR', 'FRR', 'EER']
            our_values = [our_metrics['far'], our_metrics['frr'], our_metrics['eer']]
            commercial_values = [1.0, 5.0, 3.0]
            research_values = [5.0, 15.0, 10.0]
            
            x = np.arange(len(metrics))
            width = 0.25
            
            bars1 = self.ax_comp1.bar(x - width, our_values, width, label='–ù–∞—à–∞ —Å–∏—Å—Ç–µ–º–∞', color='skyblue')
            bars2 = self.ax_comp1.bar(x, commercial_values, width, label='–ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å', color='gold')
            bars3 = self.ax_comp1.bar(x + width, research_values, width, label='–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å', color='lightcoral')
            
            self.ax_comp1.set_xlabel('–ú–µ—Ç—Ä–∏–∫–∏')
            self.ax_comp1.set_ylabel('–ü—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫ (%)')
            self.ax_comp1.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º–∏')
            self.ax_comp1.set_xticks(x)
            self.ax_comp1.set_xticklabels(metrics)
            self.ax_comp1.legend()
            self.ax_comp1.grid(True, alpha=0.3)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
            for bars in [bars1, bars2, bars3]:
                for bar in bars:
                    height = bar.get_height()
                    self.ax_comp1.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                                     f'{height:.1f}%', ha='center', va='bottom', fontsize=8)
            
            # –ì—Ä–∞—Ñ–∏–∫ 2: Radar chart –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            self.ax_comp2.clear()
            
            if our_values and all(v >= 0 for v in our_values):
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è radar chart (–∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º - –º–µ–Ω—å—à–µ –ª—É—á—à–µ)
                max_val = max(max(our_values), max(research_values))
                normalized_our = [(max_val - v) / max_val for v in our_values]
                normalized_research = [(max_val - v) / max_val for v in research_values]
                
                angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
                angles += angles[:1]  # –ó–∞–º—ã–∫–∞–µ–º –∫—Ä—É–≥
                
                normalized_our += normalized_our[:1]
                normalized_research += normalized_research[:1]
                
                self.ax_comp2 = plt.subplot(122, projection='polar')
                self.ax_comp2.plot(angles, normalized_our, 'o-', linewidth=2, label='–ù–∞—à–∞ —Å–∏—Å—Ç–µ–º–∞', color='blue')
                self.ax_comp2.fill(angles, normalized_our, alpha=0.25, color='blue')
                self.ax_comp2.plot(angles, normalized_research, 'o-', linewidth=2, label='–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å', color='red')
                self.ax_comp2.fill(angles, normalized_research, alpha=0.25, color='red')
                
                self.ax_comp2.set_xticks(angles[:-1])
                self.ax_comp2.set_xticklabels(metrics)
                self.ax_comp2.set_ylim(0, 1)
                self.ax_comp2.set_title('–ü—Ä–æ—Ñ–∏–ª—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n(–±–æ–ª—å—à–µ = –ª—É—á—à–µ)', pad=20)
                self.ax_comp2.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
            
            self.fig_comp.tight_layout()
            self.canvas_comp.draw()
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: {e}")
    
    def refresh_data(self):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            self.training_samples = self.db.get_user_training_samples(self.user.id)
            self.auth_attempts = self.db.get_auth_attempts(self.user.id, limit=100)
            self.model_info = self.model_manager.get_model_info(self.user.id)
            
            # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∞–Ω–∞–ª–∏–∑—ã
            self.load_enhanced_statistics()
            
            messagebox.showinfo("–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ", "–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω—ã!")
            
        except Exception as e:
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
    
    def optimize_model(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏"""
        try:
            if len(self.training_samples) < 30:
                messagebox.showwarning("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ", 
                                     "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏. –°–æ–±–µ—Ä–∏—Ç–µ –º–∏–Ω–∏–º—É–º 30 –æ–±—Ä–∞–∑—Ü–æ–≤.")
                return
            
            if messagebox.askyesno("–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏", 
                                 "–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –º–æ–¥–µ–ª–∏?\n–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç."):
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
                success, accuracy, message = self.model_manager.train_user_model(
                    self.user.id, 
                    use_enhanced_training=True
                )
                
                if success:
                    messagebox.showinfo("–£—Å–ø–µ—Ö", f"–ú–æ–¥–µ–ª—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞!\n–ù–æ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy:.1%}")
                    self.refresh_data()
                else:
                    messagebox.showerror("–û—à–∏–±–∫–∞", f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {message}")
        
        except Exception as e:
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {e}")
    
    def export_detailed_report(self):
        """–≠–∫—Å–ø–æ—Ä—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        try:
            from tkinter import filedialog
            
            filename = filedialog.asksaveasfilename(
                defaultextension=".txt",
                filetypes=[("–¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã", "*.txt"), ("JSON —Ñ–∞–π–ª—ã", "*.json"), ("–í—Å–µ —Ñ–∞–π–ª—ã", "*.*")],
                title="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç"
            )
            
            if filename:
                # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –≤ –æ–¥–∏–Ω –æ—Ç—á–µ—Ç
                full_report = self.generate_full_report()
                
                if filename.endswith('.json'):
                    # –≠–∫—Å–ø–æ—Ä—Ç –≤ JSON
                    report_data = self.collect_report_data()
                    with open(filename, 'w', encoding='utf-8') as f:
                        json.dump(report_data, f, indent=2, ensure_ascii=False, default=str)
                else:
                    # –≠–∫—Å–ø–æ—Ä—Ç –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
                    with open(filename, 'w', encoding='utf-8') as f:
                        f.write(full_report)
                
                messagebox.showinfo("–≠–∫—Å–ø–æ—Ä—Ç", f"–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {filename}")
        
        except Exception as e:
            messagebox.showerror("–û—à–∏–±–∫–∞", f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞: {e}")
    
    def generate_full_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        report_sections = [
            "–î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ü–û –ë–ò–û–ú–ï–¢–†–ò–ß–ï–°–ö–û–ô –°–ò–°–¢–ï–ú–ï",
            "=" * 60,
            f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {self.user.username}",
            f"–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}",
            f"–¢–∏–ø –º–æ–¥–µ–ª–∏: {self.model_info.get('model_type', 'none').upper()}",
            "",
            "1. –ê–ù–ê–õ–ò–ó –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò",
            "-" * 30
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–∞–∂–¥–æ–π –≤–∫–ª–∞–¥–∫–∏
        try:
            # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            if hasattr(self, 'performance_text'):
                performance_content = self.performance_text.get('1.0', tk.END).strip()
                if performance_content:
                    report_sections.append(performance_content)
            
            report_sections.extend(["", "2. –ü–û–í–ï–î–ï–ù–ß–ï–°–ö–ò–ï –ü–ê–¢–¢–ï–†–ù–´", "-" * 30])
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω—ã
            if hasattr(self, 'patterns_text'):
                patterns_content = self.patterns_text.get('1.0', tk.END).strip()
                if patterns_content:
                    report_sections.append(patterns_content)
            
            report_sections.extend(["", "3. –ê–ù–ê–õ–ò–ó –ë–ï–ó–û–ü–ê–°–ù–û–°–¢–ò", "-" * 30])
            
            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
            if hasattr(self, 'security_text'):
                security_content = self.security_text.get('1.0', tk.END).strip()
                if security_content:
                    report_sections.append(security_content)
            
            report_sections.extend(["", "4. –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ú–û–î–ï–õ–ò", "-" * 30])
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
            if hasattr(self, 'model_info_text'):
                model_content = self.model_info_text.get('1.0', tk.END).strip()
                if model_content:
                    report_sections.append(model_content)
            
            report_sections.extend(["", "5. –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó", "-" * 30])
            
            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
            if hasattr(self, 'comparison_text'):
                comparison_content = self.comparison_text.get('1.0', tk.END).strip()
                if comparison_content:
                    report_sections.append(comparison_content)
            
            # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
            report_sections.extend(["", "6. –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò", "-" * 30])
            report_sections.append(self.generate_conclusion())
            
        except Exception as e:
            report_sections.append(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
        
        return "\n".join(report_sections)
    
    def collect_report_data(self) -> dict:
        """–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è JSON –æ—Ç—á–µ—Ç–∞"""
        our_metrics = self.calculate_our_metrics()
        
        return {
            "user_info": {
                "username": self.user.username,
                "user_id": self.user.id,
                "report_date": datetime.now().isoformat(),
                "model_type": self.model_info.get('model_type', 'none')
            },
            "training_data": {
                "total_samples": len(self.training_samples),
                "collection_period": {
                    "start": min(s.timestamp for s in self.training_samples).isoformat() if self.training_samples else None,
                    "end": max(s.timestamp for s in self.training_samples).isoformat() if self.training_samples else None
                }
            },
            "authentication_data": {
                "total_attempts": len(self.auth_attempts),
                "successful_attempts": sum(1 for a in self.auth_attempts if a['result']),
                "success_rate": np.mean([a['result'] for a in self.auth_attempts]) if self.auth_attempts else 0,
                "average_confidence": np.mean([a['final_confidence'] for a in self.auth_attempts]) if self.auth_attempts else 0
            },
            "security_metrics": our_metrics,
            "model_info": self.model_info,
            "recommendations": self.generate_improvement_suggestions().split('\n'),
            "system_category": self.determine_system_category(our_metrics, {
                'commercial': {'far': 1.0, 'frr': 5.0, 'eer': 3.0},
                'research': {'far': 5.0, 'frr': 15.0, 'eer': 10.0},
                'acceptable': {'far': 10.0, 'frr': 25.0, 'eer': 15.0}
            })
        }
    
    def generate_conclusion(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–∫–ª—é—á–µ–Ω–∏—è"""
        our_metrics = self.calculate_our_metrics()
        
        conclusion_parts = [
            "–û–ë–©–ï–ï –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï:",
            "",
            f"–°–∏—Å—Ç–µ–º–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:",
            f"‚Ä¢ FAR: {our_metrics['far']:.1f}%",
            f"‚Ä¢ FRR: {our_metrics['frr']:.1f}%", 
            f"‚Ä¢ EER: {our_metrics['eer']:.1f}%",
            "",
            "–ö–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:",
        ]
        
        if our_metrics['eer'] <= 10:
            conclusion_parts.append("‚úÖ –û–¢–õ–ò–ß–ù–û–ï - —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º")
        elif our_metrics['eer'] <= 15:
            conclusion_parts.append("‚úÖ –•–û–†–û–®–ï–ï - –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã")
        elif our_metrics['eer'] <= 25:
            conclusion_parts.append("‚ö†Ô∏è –£–î–û–í–õ–ï–¢–í–û–†–ò–¢–ï–õ–¨–ù–û–ï - –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π")
        else:
            conclusion_parts.append("‚ö†Ô∏è –¢–†–ï–ë–£–ï–¢ –î–û–†–ê–ë–û–¢–ö–ò - –Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –±–∞–∑–æ–≤–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ")
        
        conclusion_parts.extend([
            "",
            "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏—è:",
            "‚Ä¢ –£–≤–µ–ª–∏—á–∏—Ç—å –æ–±—ä–µ–º –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö",
            "‚Ä¢ –ü—Ä–æ–≤–µ—Å—Ç–∏ –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤",
            "‚Ä¢ –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è",
            "‚Ä¢ –ü—Ä–æ–≤–µ—Å—Ç–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –±–æ–ª—å—à–µ–π –≥—Ä—É–ø–ø–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π",
            "",
            "–°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤ —Ä–∞–º–∫–∞—Ö –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã."
        ])
        
        return "\n".join(conclusion_parts)
    

    # –î–æ–±–∞–≤–∏—Ç—å –≤ gui/enhanced_model_stats_window.py - –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ ROC –∞–Ω–∞–ª–∏–∑–∞

    def create_roc_analysis_tab(self):
        """–ù–æ–≤–∞—è –≤–∫–ª–∞–¥–∫–∞ ROC-–∞–Ω–∞–ª–∏–∑–∞"""
        frame = ttk.Frame(self.notebook, padding=15)
        self.notebook.add(frame, text="üìà ROC –ê–Ω–∞–ª–∏–∑")
    
        # –û–ø–∏—Å–∞–Ω–∏–µ ROC –∞–Ω–∞–ª–∏–∑–∞
        description_frame = ttk.LabelFrame(frame, text="üìñ –ß—Ç–æ —Ç–∞–∫–æ–µ ROC –∞–Ω–∞–ª–∏–∑?", padding=10)
        description_frame.pack(fill=tk.X, pady=(0, 10))
    
        description_text = """ROC (Receiver Operating Characteristic) –∫—Ä–∏–≤–∞—è –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.
    
    üéØ –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è:
    ‚Ä¢ TPR (True Positive Rate) = Sensitivity = –î–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–∏–Ω—è—Ç—ã—Ö "—Å–≤–æ–∏—Ö" = 1 - FRR
    ‚Ä¢ FPR (False Positive Rate) = 1 - Specificity = –î–æ–ª—è –æ—à–∏–±–æ—á–Ω–æ –ø—Ä–∏–Ω—è—Ç—ã—Ö "—á—É–∂–∏—Ö" = FAR
    ‚Ä¢ AUC (Area Under Curve) = –ü–ª–æ—â–∞–¥—å –ø–æ–¥ ROC –∫—Ä–∏–≤–æ–π (0.5 = —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å, 1.0 = –∏–¥–µ–∞–ª)

    üìä –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è AUC:
    ‚Ä¢ 0.9-1.0: –û—Ç–ª–∏—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
    ‚Ä¢ 0.8-0.9: –•–æ—Ä–æ—à–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è  
    ‚Ä¢ 0.7-0.8: –£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–∞—è
    ‚Ä¢ 0.6-0.7: –°–ª–∞–±–∞—è
    ‚Ä¢ 0.5-0.6: –ù–µ—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–∞—è"""
    
        desc_label = ttk.Label(description_frame, text=description_text, justify=tk.LEFT, 
                            font=(FONT_FAMILY, 9))
        desc_label.pack(anchor=tk.W)
    
        # ROC –≥—Ä–∞—Ñ–∏–∫
        self.fig_roc, (self.ax_roc1, self.ax_roc2) = plt.subplots(1, 2, figsize=(14, 6))
        self.canvas_roc = FigureCanvasTkAgg(self.fig_roc, frame)
        self.canvas_roc.get_tk_widget().pack(fill=tk.BOTH, expand=True)

    def load_roc_analysis(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ ROC –∞–Ω–∞–ª–∏–∑–∞ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –º–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            model = self.model_manager._get_user_model(self.user.id)
            if not model or not hasattr(model, 'is_trained') or not model.is_trained:
                self.ax_roc1.text(0.5, 0.5, '–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞\n–¢—Ä–µ–±—É–µ—Ç—Å—è –∑–∞–≤–µ—Ä—à–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ', 
                                ha='center', va='center', transform=self.ax_roc1.transAxes, 
                                fontsize=14, bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow"))
                self.ax_roc2.text(0.5, 0.5, '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö\n–¥–ª—è ROC –∞–Ω–∞–ª–∏–∑–∞', 
                                ha='center', va='center', transform=self.ax_roc2.transAxes, 
                                fontsize=14, bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow"))
                self.canvas_roc.draw()
                return

            print(f"\nüìà –ó–ê–ü–£–°–ö ROC –ê–ù–ê–õ–ò–ó–ê –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {self.user.username}")

            # –ü–æ–ª—É—á–∞–µ–º –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            training_samples = self.db.get_user_training_samples(self.user.id)
            if len(training_samples) < 10:
                self.ax_roc1.text(0.5, 0.5, f'–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {len(training_samples)}\n–ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 10', 
                                ha='center', va='center', transform=self.ax_roc1.transAxes, fontsize=14)
                self.canvas_roc.draw()
                return

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            from ml.feature_extractor import FeatureExtractor
            extractor = FeatureExtractor()
            X_positive = extractor.extract_features_from_samples(training_samples)
        
            print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(X_positive)} –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤")

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–∏–º–∏—Ç–∏—Ä—É–µ–º –¥—Ä—É–≥–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π)
            X_negative = self._generate_roc_negatives(X_positive)
            print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(X_negative)} –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤")

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            X_test = np.vstack([X_positive, X_negative])
            y_true = np.hstack([
                np.ones(len(X_positive)),   # 1 = –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ (–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å)
                np.zeros(len(X_negative))   # 0 = —á—É–∂–∏–µ –¥–∞–Ω–Ω—ã–µ (–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∫–ª–∞—Å—Å)
            ])

            print(f"üìä –¢–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä: {len(X_test)} –æ–±—Ä–∞–∑—Ü–æ–≤ ({len(X_positive)} –≤–∞—à–∏—Ö + {len(X_negative)} —á—É–∂–∏—Ö)")

            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞
            confidence_scores = []
            predictions = []

            for i, sample in enumerate(X_test):
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                    if hasattr(model, 'authenticate'):
                        # –î–ª—è –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
                        is_auth, confidence, _ = model.authenticate(sample, threshold=0.5)
                    elif hasattr(model, 'predict_with_confidence'):
                        # –î–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –º–æ–¥–µ–ª–∏
                        is_auth, confidence, _ = model.predict_with_confidence(sample)
                    else:
                        # –ü—Ä—è–º–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ sklearn –º–æ–¥–µ–ª–∏
                        if hasattr(model, 'model'):
                            proba = model.model.predict_proba(sample.reshape(1, -1))[0]
                            confidence = proba[1] if len(proba) > 1 else proba[0]
                            is_auth = confidence >= 0.5
                        else:
                            confidence = 0.5
                            is_auth = False

                    confidence_scores.append(confidence)
                    predictions.append(1 if is_auth else 0)

                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –æ–±—Ä–∞–∑—Ü–∞ {i}: {e}")
                    confidence_scores.append(0.5)
                    predictions.append(0)

            confidence_scores = np.array(confidence_scores)
            print(f"üìà –ü–æ–ª—É—á–µ–Ω—ã –æ—Ü–µ–Ω–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: –º–∏–Ω={np.min(confidence_scores):.3f}, –º–∞–∫—Å={np.max(confidence_scores):.3f}")

            # –°—Ç—Ä–æ–∏–º ROC –∫—Ä–∏–≤—É—é
            from sklearn.metrics import roc_curve, auc
            fpr, tpr, thresholds = roc_curve(y_true, confidence_scores)
            roc_auc = auc(fpr, tpr)

            print(f"üéØ AUC = {roc_auc:.3f}")

            # –ì—Ä–∞—Ñ–∏–∫ 1: ROC –∫—Ä–∏–≤–∞—è
            self.ax_roc1.clear()
            self.ax_roc1.plot(fpr, tpr, color='darkorange', lw=3, 
                            label=f'ROC –∫—Ä–∏–≤–∞—è (AUC = {roc_auc:.3f})')
            self.ax_roc1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', 
                            label='–°–ª—É—á–∞–π–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (AUC = 0.5)')

            # –û—Ç–º–µ—á–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é —Ç–æ—á–∫—É (–º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ–º TPR - FPR)
            optimal_idx = np.argmax(tpr - fpr)
            optimal_threshold = thresholds[optimal_idx]
            optimal_fpr = fpr[optimal_idx]
            optimal_tpr = tpr[optimal_idx]

            self.ax_roc1.plot(optimal_fpr, optimal_tpr, 'ro', markersize=10, 
                            label=f'–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–∫–∞ (–ø–æ—Ä–æ–≥ = {optimal_threshold:.2f})')

            # –û—Ç–º–µ—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –ø–æ—Ä–æ–≥ (–æ–±—ã—á–Ω–æ 0.75)
            current_threshold = 0.75
            current_idx = np.argmin(np.abs(thresholds - current_threshold))
            if current_idx < len(fpr):
                self.ax_roc1.plot(fpr[current_idx], tpr[current_idx], 'gs', markersize=8,
                                label=f'–¢–µ–∫—É—â–∏–π –ø–æ—Ä–æ–≥ (0.75)')

            self.ax_roc1.set_xlim([0.0, 1.0])
            self.ax_roc1.set_ylim([0.0, 1.05])
            self.ax_roc1.set_xlabel('False Positive Rate (FAR)', fontsize=12)
            self.ax_roc1.set_ylabel('True Positive Rate (1 - FRR)', fontsize=12)
            self.ax_roc1.set_title(f'ROC –ö—Ä–∏–≤–∞—è –¥–ª—è {self.user.username}', fontsize=14, fontweight='bold')
            self.ax_roc1.legend(loc="lower right", fontsize=10)
            self.ax_roc1.grid(True, alpha=0.3)

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é AUC
            if roc_auc >= 0.9:
                auc_text = "–û—Ç–ª–∏—á–Ω–∞—è –º–æ–¥–µ–ª—å!"
                auc_color = "green"
            elif roc_auc >= 0.8:
                auc_text = "–•–æ—Ä–æ—à–∞—è –º–æ–¥–µ–ª—å"
                auc_color = "blue"
            elif roc_auc >= 0.7:
                auc_text = "–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–∞—è"
                auc_color = "orange"
            else:
                auc_text = "–¢—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è"
                auc_color = "red"

            self.ax_roc1.text(0.6, 0.2, f'{auc_text}\nAUC = {roc_auc:.3f}', 
                            transform=self.ax_roc1.transAxes, fontsize=12, 
                            bbox=dict(boxstyle="round,pad=0.3", facecolor=auc_color, alpha=0.3))

            # –ì—Ä–∞—Ñ–∏–∫ 2: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            self.ax_roc2.clear()

            positive_scores = confidence_scores[y_true == 1]  # –í–∞—à–∏ –æ—Ü–µ–Ω–∫–∏
            negative_scores = confidence_scores[y_true == 0]  # –ß—É–∂–∏–µ –æ—Ü–µ–Ω–∫–∏

            # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
            self.ax_roc2.hist(negative_scores, bins=20, alpha=0.6, color='red', 
                            label=f'–ß—É–∂–∏–µ –¥–∞–Ω–Ω—ã–µ (n={len(negative_scores)})', 
                            density=True, edgecolor='darkred')
            self.ax_roc2.hist(positive_scores, bins=20, alpha=0.6, color='green', 
                            label=f'–í–∞—à–∏ –¥–∞–Ω–Ω—ã–µ (n={len(positive_scores)})', 
                            density=True, edgecolor='darkgreen')

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            pos_mean, pos_std = np.mean(positive_scores), np.std(positive_scores)
            neg_mean, neg_std = np.mean(negative_scores), np.std(negative_scores)

            # –°—Ä–µ–¥–Ω–∏–µ –ª–∏–Ω–∏–∏
            self.ax_roc2.axvline(pos_mean, color='darkgreen', linestyle='-', linewidth=2, 
                            alpha=0.8, label=f'–°—Ä–µ–¥–Ω–µ–µ –≤–∞—à–∏—Ö: {pos_mean:.3f}')
            self.ax_roc2.axvline(neg_mean, color='darkred', linestyle='-', linewidth=2, 
                            alpha=0.8, label=f'–°—Ä–µ–¥–Ω–µ–µ —á—É–∂–∏—Ö: {neg_mean:.3f}')

            # –ü–æ—Ä–æ–≥
            self.ax_roc2.axvline(current_threshold, color='black', linestyle='--', linewidth=2, 
                            alpha=0.8, label=f'–ü–æ—Ä–æ–≥: {current_threshold}')

            self.ax_roc2.set_xlabel('–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã', fontsize=12)
            self.ax_roc2.set_ylabel('–ü–ª–æ—Ç–Ω–æ—Å—Ç—å', fontsize=12)
            self.ax_roc2.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏', fontsize=14, fontweight='bold')
            self.ax_roc2.legend(loc='upper right', fontsize=9)
            self.ax_roc2.grid(True, alpha=0.3)

            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç–∏
            separation = abs(pos_mean - neg_mean)
            overlap = self._calculate_overlap(positive_scores, negative_scores)
        
            stats_text = f'–†–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç—å: {separation:.3f}\n–ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ: {overlap:.1%}\n–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {"–í—ã—Å–æ–∫–∞—è" if separation > 0.3 else "–°—Ä–µ–¥–Ω—è—è" if separation > 0.15 else "–ù–∏–∑–∫–∞—è"}'
        
            self.ax_roc2.text(0.02, 0.98, stats_text,
                            transform=self.ax_roc2.transAxes, fontsize=10, 
                            verticalalignment='top',
                            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow", alpha=0.8))

            self.fig_roc.tight_layout()
            self.canvas_roc.draw()

            # –í—ã–≤–æ–¥–∏–º –ø–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤ –∫–æ–Ω—Å–æ–ª—å
            print(f"\nüìä ROC –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù:")
            print(f"  AUC: {roc_auc:.3f} ({auc_text})")
            print(f"  –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {optimal_threshold:.3f}")
            print(f"  –ü—Ä–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–º –ø–æ—Ä–æ–≥–µ: TPR={optimal_tpr:.3f}, FPR={optimal_fpr:.3f}")
            print(f"  –†–∞–∑–¥–µ–ª–∏–º–æ—Å—Ç—å –∫–ª–∞—Å—Å–æ–≤: {separation:.3f}")
            print(f"  –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π: {overlap:.1%}")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ ROC –∞–Ω–∞–ª–∏–∑–∞: {e}")
            import traceback
            traceback.print_exc()
        
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ
            self.ax_roc1.text(0.5, 0.5, f'–û—à–∏–±–∫–∞ ROC –∞–Ω–∞–ª–∏–∑–∞:\n{str(e)}', 
                            ha='center', va='center', transform=self.ax_roc1.transAxes, 
                            fontsize=12, bbox=dict(boxstyle="round,pad=0.3", facecolor="lightcoral"))
            self.canvas_roc.draw()

    def _generate_roc_negatives(self, X_positive: np.ndarray) -> np.ndarray:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è ROC –∞–Ω–∞–ª–∏–∑–∞"""
        n_samples = len(X_positive)
        mean = np.mean(X_positive, axis=0)
        std = np.std(X_positive, axis=0)
    
        # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å
        std = np.maximum(std, mean * 0.1)
    
        negatives = []
    
        # 30% - –±–ª–∏–∑–∫–∏–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã (—Å–ª–æ–∂–Ω—ã–µ –¥–ª—è —Ä–∞–∑–ª–∏—á–µ–Ω–∏—è)
        close_count = int(n_samples * 0.3)
        for i in range(close_count):
            sample = mean + np.random.normal(0, std * 1.5)
            sample = np.maximum(sample, mean * 0.1)
            negatives.append(sample)
    
        # 40% - —É–º–µ—Ä–µ–Ω–Ω–æ –æ—Ç–ª–∏—á–∞—é—â–∏–µ—Å—è
        moderate_count = int(n_samples * 0.4)
        for i in range(moderate_count):
            factors = np.random.uniform(0.5, 2.0, size=len(mean))
            sample = mean * factors
            noise = np.random.normal(0, std * 0.8)
            sample = sample + noise
            sample = np.maximum(sample, mean * 0.05)
            negatives.append(sample)
    
        # 30% - —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—â–∏–µ—Å—è
        far_count = n_samples - close_count - moderate_count
        for i in range(far_count):
            factors = np.random.uniform(0.2, 4.0, size=len(mean))
            sample = mean * factors
            noise = np.random.normal(0, std * 1.2)
            sample = sample + noise
            sample = np.maximum(sample, mean * 0.01)
            negatives.append(sample)
    
        return np.array(negatives)

    def _calculate_overlap(self, dist1: np.ndarray, dist2: np.ndarray) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –¥–≤—É—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π"""
        min_val = min(np.min(dist1), np.min(dist2))
        max_val = max(np.max(dist1), np.max(dist2))
    
        # –°–æ–∑–¥–∞–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
        bins = np.linspace(min_val, max_val, 50)
        hist1, _ = np.histogram(dist1, bins=bins, density=True)
        hist2, _ = np.histogram(dist2, bins=bins, density=True)
    
        # –í—ã—á–∏—Å–ª—è–µ–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –∫–∞–∫ –º–∏–Ω–∏–º—É–º –¥–≤—É—Ö –ø–ª–æ—Ç–Ω–æ—Å—Ç–µ–π
        overlap = np.sum(np.minimum(hist1, hist2)) * (bins[1] - bins[0])
        return overlap    


def main():
    """–¢–µ—Å—Ç–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
    root = tk.Tk()
    root.withdraw()  # –°–∫—Ä—ã–≤–∞–µ–º –≥–ª–∞–≤–Ω–æ–µ –æ–∫–Ω–æ
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    from models.user import User
    from auth.keystroke_auth import KeystrokeAuthenticator
    
    test_user = User(
        username="test_user",
        password_hash="test_hash",
        salt="test_salt",
        id=1,
        is_trained=True
    )
    
    keystroke_auth = KeystrokeAuthenticator()
    
    # –°–æ–∑–¥–∞–µ–º –æ–∫–Ω–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    stats_window = EnhancedModelStatsWindow(root, test_user, keystroke_auth)
    
    root.mainloop()


if __name__ == "__main__":
    main()