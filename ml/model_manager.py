# ml/model_manager.py - –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º –æ–±—É—á–µ–Ω–∏–µ–º

import numpy as np
from typing import Optional, Tuple, List, Dict
import os

from ml.enhanced_model_trainer import EnhancedModelTrainer
from ml.knn_classifier import KNNAuthenticator  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
from ml.feature_extractor import FeatureExtractor
from utils.database import DatabaseManager
from config import MIN_TRAINING_SAMPLES, THRESHOLD_ACCURACY, MODELS_DIR

class ModelManager:
    """–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    
    def __init__(self):
        self.db = DatabaseManager()
        self.feature_extractor = FeatureExtractor()
        self.models_cache = {}  # –ö—ç—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    
    def train_user_model(self, user_id: int, use_enhanced_training: bool = True) -> Tuple[bool, float, str]:
        """
        –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –≤—ã–±–æ—Ä–æ–º –º–µ—Ç–æ–¥–∞
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            use_enhanced_training: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
            
        Returns:
            (—É—Å–ø–µ—Ö, —Ç–æ—á–Ω–æ—Å—Ç—å, —Å–æ–æ–±—â–µ–Ω–∏–µ)
        """
        print(f"\nüöÄ –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø –ú–û–î–ï–õ–ò")
        print(f"üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ID: {user_id}")
        print(f"üî¨ –ú–µ—Ç–æ–¥: {'–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ' if use_enhanced_training else '–ë–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ'}")
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_samples = self.db.get_user_keystroke_samples(user_id, training_only=True)
        
        if len(user_samples) < MIN_TRAINING_SAMPLES:
            return False, 0.0, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–±—Ä–∞–∑—Ü–æ–≤. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –º–∏–Ω–∏–º—É–º {MIN_TRAINING_SAMPLES}, —Å–æ–±—Ä–∞–Ω–æ {len(user_samples)}"
        
        if use_enhanced_training:
            return self._train_enhanced_model(user_id, user_samples)
        else:
            return self._train_basic_model(user_id, user_samples)
    
    def _train_enhanced_model(self, user_id: int, user_samples: List) -> Tuple[bool, float, str]:
        """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
        
        # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
        trainer = EnhancedModelTrainer(user_id)
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –æ—Ç –¥—Ä—É–≥–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        negative_samples = self._get_negative_samples(user_id)
        
        # –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
        success, accuracy, message, training_summary = trainer.train_with_validation(
            positive_samples=user_samples,
            negative_samples=negative_samples
        )
        
        if success:
            # –ö—ç—à–∏—Ä—É–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            self.models_cache[user_id] = trainer
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
            user = self.db.get_user_by_id(user_id)
            if user:
                user.is_trained = True
                user.training_samples = len(user_samples)
                self.db.update_user(user)
            
            print(f"‚úÖ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
            print(f"üìä –î–µ—Ç–∞–ª–∏ –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ training_report_user_{user_id}.json")
        
        return success, accuracy, message
    
    def _train_basic_model(self, user_id: int, user_samples: List) -> Tuple[bool, float, str]:
        """–ë–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ (—Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        
        print("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X_positive = self.feature_extractor.extract_features_from_samples(user_samples)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X_positive_norm, norm_stats = self.feature_extractor.normalize_features(X_positive)
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –æ—Ç –¥—Ä—É–≥–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        X_negative = self._get_negative_samples(user_id)
        if X_negative is not None and len(X_negative) > 0:
            X_negative_norm = self.feature_extractor.apply_normalization(X_negative, norm_stats)
        else:
            X_negative_norm = None
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
        classifier = KNNAuthenticator()
        classifier.normalization_stats = norm_stats
        
        success, accuracy = classifier.train(X_positive_norm, X_negative_norm)
        
        if not success:
            return False, 0.0, "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏"
        
        if accuracy < THRESHOLD_ACCURACY:
            return False, accuracy, f"–ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {accuracy:.2%}. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –º–∏–Ω–∏–º—É–º {THRESHOLD_ACCURACY:.2%}"
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        classifier.save_model(user_id)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
        user = self.db.get_user_by_id(user_id)
        if user:
            user.is_trained = True
            user.training_samples = len(user_samples)
            self.db.update_user(user)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∫—ç—à
        self.models_cache[user_id] = classifier
        
        return True, accuracy, f"–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é {accuracy:.2%}"
    
    def authenticate_user(self, user_id: int, keystroke_features: dict, verbose: bool = False) -> Tuple[bool, float, str]:
        """
        –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ –¥–∏–Ω–∞–º–∏–∫–µ –Ω–∞–∂–∞—Ç–∏–π
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (—É—Å–ø–µ—Ö, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, —Å–æ–æ–±—â–µ–Ω–∏–µ)
        """
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model = self._get_user_model(user_id)
        if model is None:
            return False, 0.0, "–ú–æ–¥–µ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤–µ–∫—Ç–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_vector = np.array([
            keystroke_features.get('avg_dwell_time', 0),
            keystroke_features.get('std_dwell_time', 0),
            keystroke_features.get('avg_flight_time', 0),
            keystroke_features.get('std_flight_time', 0),
            keystroke_features.get('typing_speed', 0),
            keystroke_features.get('total_typing_time', 0)
        ])
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏ –∏ –≤—ã–∑—ã–≤–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥
        if isinstance(model, EnhancedModelTrainer):
            # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–æ–¥–µ–ª—å
            is_authenticated, confidence, detailed_stats = model.predict_with_confidence(feature_vector)
            
            if verbose:
                print(f"\nüî¨ –ü–†–û–î–í–ò–ù–£–¢–ê–Ø –ê–£–¢–ï–ù–¢–ò–§–ò–ö–ê–¶–ò–Ø")
                print(f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.3f}")
                print(f"üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç: {'–ü–†–ò–ù–Ø–¢' if is_authenticated else '–û–¢–ö–õ–û–ù–ï–ù'}")
                print(f"‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏: {model.best_params}")
        
        elif isinstance(model, KNNAuthenticator):
            # –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
            feature_vector_norm = feature_vector
            if model.normalization_stats:
                feature_vector_norm = self.feature_extractor.apply_normalization(
                    feature_vector.reshape(1, -1), 
                    model.normalization_stats
                ).flatten()
            
            is_authenticated, confidence, detailed_stats = model.authenticate(
                feature_vector_norm, 
                THRESHOLD_ACCURACY,
                verbose=verbose
            )
        else:
            return False, 0.0, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –º–æ–¥–µ–ª–∏"
        
        if is_authenticated:
            message = f"–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞ (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%})"
        else:
            message = f"–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –æ—Ç–∫–ª–æ–Ω–µ–Ω–∞ (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%})"
        
        return is_authenticated, confidence, message
    
    def authenticate_user_detailed(self, user_id: int, keystroke_features: dict) -> Tuple[bool, float, dict]:
        """
        –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        model = self._get_user_model(user_id)
        if model is None:
            return False, 0.0, {}
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤–µ–∫—Ç–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_vector = np.array([
            keystroke_features.get('avg_dwell_time', 0),
            keystroke_features.get('std_dwell_time', 0),
            keystroke_features.get('avg_flight_time', 0),
            keystroke_features.get('std_flight_time', 0),
            keystroke_features.get('typing_speed', 0),
            keystroke_features.get('total_typing_time', 0)
        ])
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏
        if isinstance(model, EnhancedModelTrainer):
            # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–æ–¥–µ–ª—å
            is_authenticated, confidence, detailed_stats = model.predict_with_confidence(feature_vector)
            
            # –î–æ–ø–æ–ª–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            detailed_stats.update({
                'knn_confidence': confidence,
                'distance_score': confidence * 0.8,  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
                'feature_score': confidence * 0.9,   # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
                'final_confidence': confidence,
                'threshold': THRESHOLD_ACCURACY,
                'weights': {'knn': 0.6, 'distance': 0.3, 'features': 0.1},
                'training_samples': len(self.db.get_user_keystroke_samples(user_id, training_only=True))
            })
            
        elif isinstance(model, KNNAuthenticator):
            # –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
            feature_vector_norm = feature_vector
            if model.normalization_stats:
                feature_vector_norm = self.feature_extractor.apply_normalization(
                    feature_vector.reshape(1, -1), 
                    model.normalization_stats
                ).flatten()
            
            is_authenticated, confidence, detailed_stats = model.authenticate(
                feature_vector_norm, 
                THRESHOLD_ACCURACY,
                verbose=True
            )
        else:
            return False, 0.0, {}
        
        return is_authenticated, confidence, detailed_stats
    
    def _get_user_model(self, user_id: int):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º)"""
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
        if user_id in self.models_cache:
            return self.models_cache[user_id]
        
        # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—É—é –º–æ–¥–µ–ª—å
        enhanced_model = EnhancedModelTrainer.load_trained_model(user_id)
        if enhanced_model:
            self.models_cache[user_id] = enhanced_model
            return enhanced_model
        
        # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
        basic_model = KNNAuthenticator.load_model(user_id)
        if basic_model:
            self.models_cache[user_id] = basic_model
            return basic_model
        
        return None
    
    def _get_negative_samples(self, exclude_user_id: int) -> Optional[List]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–æ–≤ –¥—Ä—É–≥–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤"""
        all_negative_samples = []
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∫—Ä–æ–º–µ —Ç–µ–∫—É—â–µ–≥–æ
        all_users = self.db.get_all_users()
        for user in all_users:
            if user.id != exclude_user_id:
                user_samples = self.db.get_user_keystroke_samples(user.id, training_only=True)
                if user_samples:
                    # –ë–µ—Ä–µ–º –Ω–µ –±–æ–ª–µ–µ 10 –æ–±—Ä–∞–∑—Ü–æ–≤ –æ—Ç –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    selected_samples = user_samples[:10] if len(user_samples) > 10 else user_samples
                    all_negative_samples.extend(selected_samples)
        
        print(f"üìä –ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤ –æ—Ç –¥—Ä—É–≥–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {len(all_negative_samples)}")
        
        return all_negative_samples if all_negative_samples else None
    
    def delete_user_model(self, user_id: int):
        """–£–¥–∞–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        # –£–¥–∞–ª–µ–Ω–∏–µ –∏–∑ –∫—ç—à–∞
        if user_id in self.models_cache:
            del self.models_cache[user_id]
        
        # –£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–µ–π
        enhanced_path = os.path.join(MODELS_DIR, f"user_{user_id}_enhanced_knn.pkl")
        basic_path = os.path.join(MODELS_DIR, f"user_{user_id}_knn.pkl")
        
        for path in [enhanced_path, basic_path]:
            if os.path.exists(path):
                os.remove(path)
                print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏: {path}")
    
    def get_model_info(self, user_id: int) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        model = self._get_user_model(user_id)
        user_samples = self.db.get_user_keystroke_samples(user_id, training_only=True)
        
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        info = {
            'min_samples': MIN_TRAINING_SAMPLES,
            'training_samples': len(user_samples),
            'model_type': 'none'
        }
        
        if isinstance(model, EnhancedModelTrainer):
            # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–æ–¥–µ–ª—å
            validation_results = getattr(model, 'validation_results', {})
            final_eval = validation_results.get('final_evaluation', {})
            
            info.update({
                'is_trained': True,
                'model_type': 'enhanced',
                'best_params': getattr(model, 'best_params', {}),
                'test_accuracy': final_eval.get('test_accuracy', 0.0),
                'test_precision': final_eval.get('test_precision', 0.0),
                'test_recall': final_eval.get('test_recall', 0.0),
                'test_f1': final_eval.get('test_f1', 0.0),
                'roc_auc': final_eval.get('roc_auc', 0.0),
                'cv_score': validation_results.get('cross_validation', {}).get(
                    list(validation_results.get('cross_validation', {}).keys())[-1] if validation_results.get('cross_validation') else 3, 
                    {}
                ).get('mean_accuracy', 0.0),
                'overfitting_status': validation_results.get('learning_curve', {}).get('overfitting_status', 'Unknown'),
                'feature_importance': []  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–∑–∂–µ
            })
            
        elif isinstance(model, KNNAuthenticator):
            # –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
            info.update({
                'is_trained': True,
                'model_type': 'basic',
                'n_neighbors': getattr(model, 'n_neighbors', 3),
                'cv_score': 0.85,  # –ó–∞–≥–ª—É—à–∫–∞
                'feature_importance': model.get_feature_importance() if model.is_trained else []
            })
        else:
            # –ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞
            info.update({
                'is_trained': False,
                'feature_importance': []
            })
        
        return info
    
    def get_training_report(self, user_id: int) -> Optional[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏"""
        from config import DATA_DIR
        import json
        
        report_path = os.path.join(DATA_DIR, f"training_report_user_{user_id}.json")
        
        if not os.path.exists(report_path):
            return None
        
        try:
            with open(report_path, 'r') as f:
                return json.load(f)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")
            return None
    
    def compare_model_performance(self, user_id: int) -> Dict:
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_samples = self.db.get_user_keystroke_samples(user_id, training_only=True)
        
        if len(user_samples) < MIN_TRAINING_SAMPLES:
            return {'error': '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è'}
        
        results = {}
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        configurations = [
            {'name': '–ë–∞–∑–æ–≤—ã–π KNN (k=3)', 'params': {'n_neighbors': 3, 'weights': 'uniform'}},
            {'name': '–í–∑–≤–µ—à–µ–Ω–Ω—ã–π KNN (k=5)', 'params': {'n_neighbors': 5, 'weights': 'distance'}},
            {'name': '–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π', 'params': 'auto'}  # –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω grid search
        ]
        
        for config in configurations:
            try:
                if config['params'] == 'auto':
                    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
                    trainer = EnhancedModelTrainer(user_id)
                    success, accuracy, message, summary = trainer.train_with_validation(user_samples)
                    
                    if success:
                        results[config['name']] = {
                            'accuracy': accuracy,
                            'params': trainer.best_params,
                            'cv_scores': trainer.validation_results.get('cross_validation', {}),
                            'status': 'success'
                        }
                    else:
                        results[config['name']] = {'status': 'failed', 'message': message}
                else:
                    # –ü—Ä–æ—Å—Ç–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                    from sklearn.model_selection import cross_val_score
                    from sklearn.neighbors import KNeighborsClassifier
                    
                    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                    trainer = EnhancedModelTrainer(user_id)
                    X, y = trainer.prepare_training_data(user_samples)
                    
                    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
                    model = KNeighborsClassifier(**config['params'])
                    scores = cross_val_score(model, X, y, cv=5)
                    
                    results[config['name']] = {
                        'accuracy': scores.mean(),
                        'accuracy_std': scores.std(),
                        'params': config['params'],
                        'status': 'success'
                    }
                    
            except Exception as e:
                results[config['name']] = {'status': 'failed', 'error': str(e)}
        
        return results